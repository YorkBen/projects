{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61be6332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 08:58:41,892 - INFO - __init__.py - init_logger - 58 - ini  logger file D:\\projects\\Vision\\Lib\\logs\\kernel-35b3e046-9ab6-4bd3-a3a4-136921395637.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use temp dir:d:\\znyx\\temp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 08:59:08,523 - DEBUG - tpu_cluster_resolver.py - <module> - 32 - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2022-11-08 08:59:13,245 - DEBUG - __init__.py - <module> - 47 - Creating converter from 7 to 5\n",
      "2022-11-08 08:59:13,246 - DEBUG - __init__.py - <module> - 47 - Creating converter from 5 to 7\n",
      "2022-11-08 08:59:13,246 - DEBUG - __init__.py - <module> - 47 - Creating converter from 7 to 5\n",
      "2022-11-08 08:59:13,247 - DEBUG - __init__.py - <module> - 47 - Creating converter from 5 to 7\n",
      "2022-11-08 08:59:33,428 - INFO - utils.py - _init_num_threads - 147 - Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-11-08 08:59:33,429 - INFO - utils.py - _init_num_threads - 159 - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import cv2\n",
    "\n",
    "# 添加路径，以能正常导入mbsh、trainer\n",
    "sys.path.append(r'..\\Lib\\trainer')\n",
    "\n",
    "from mbsh.core.yolo import YOLO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf008f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "  tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3bfb1",
   "metadata": {},
   "source": [
    "### 公共函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ccc62d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta1 = 4       # 用于合并间断帧\n",
    "delta2 = 2 * 18  # 用于筛选最终息肉\n",
    "fps = 18\n",
    "\n",
    "# 统计一个视频模型标记息肉开始结束帧\n",
    "def stat_ct_file(file_path):\n",
    "    ct, start, end = 0, 0, 0\n",
    "    results = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            arr = line.strip().split(',')\n",
    "            if arr[1] == '1':\n",
    "                if start == 0:\n",
    "                    start = int(arr[0][:-4])\n",
    "            else:\n",
    "                if start != 0:\n",
    "                    end = int(arr[0][:-4])\n",
    "                    if end - start >= delta1:\n",
    "                        results.append([start, end])\n",
    "                    start = 0\n",
    "                    \n",
    "        return results\n",
    "\n",
    "\n",
    "def stat_ct(data):\n",
    "    ct, start, end = 0, 0, 0\n",
    "    results = []\n",
    "    for arr in data:\n",
    "        if arr[1] == 1:\n",
    "            if start == 0:\n",
    "                start = int(arr[0][:-4])\n",
    "        else:\n",
    "            if start != 0:\n",
    "                end = int(arr[0][:-4])\n",
    "                if end - start >= delta1:\n",
    "                    results.append([start, end])\n",
    "#                 results.append([start, end])\n",
    "                start = 0\n",
    "                    \n",
    "    return results\n",
    "\n",
    "\n",
    "# 合并一个视频模型标记息肉开始结束帧\n",
    "def merge_ct(arr):\n",
    "    if len(arr) == 0:\n",
    "        return []\n",
    "    \n",
    "    results = [arr[0]]\n",
    "    for idx in range(1, len(arr)):\n",
    "        if arr[idx][0] - results[-1][1]  < delta1:\n",
    "            results[-1][1] = arr[idx][1]\n",
    "        else:\n",
    "            results.append(arr[idx])\n",
    "            \n",
    "    return results\n",
    "\n",
    "# 按照长度过滤息肉，>= 2S的才选择\n",
    "def filt_polyp(arr):\n",
    "    results = []\n",
    "    for start, end in arr:\n",
    "        if end - start >= delta1 - 1:\n",
    "            results.append([start, end])\n",
    "    \n",
    "    return results\n",
    "    \n",
    "\n",
    "# 将目录的图片名称按照名称数字从小到大排序\n",
    "def get_dir_sorted_imgs(dirs):\n",
    "    names = []\n",
    "    if isinstance(dirs, str):\n",
    "        if os.path.exists(dirs):\n",
    "            names = [int(filename[:-4]) for filename in os.listdir(dirs) if filename.endswith('.jpg')]\n",
    "    elif isinstance(dirs, list):\n",
    "        for dir in dirs:\n",
    "            if os.path.exists(dir):\n",
    "                names.extend([int(filename[:-4]) for filename in os.listdir(dir) if filename.endswith('.jpg')])\n",
    "    names = sorted(names)\n",
    "    img_names = ['%s.jpg' % name for name in names]\n",
    "    return img_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c180c6d",
   "metadata": {},
   "source": [
    "### 息肉检测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d7df660",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5'\n",
    "anchors_path = r'D:\\projects\\Vision\\polyp\\Models\\yolo_anchors_0311.txt'\n",
    "classes_path = r'D:\\projects\\Vision\\polyp\\Models\\polyp_classes.txt'\n",
    "iou = 0.1\n",
    "\n",
    "model_image_size = (352, 352)\n",
    "gpu_num = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39686ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型检测标记息肉\n",
    "def detect_polyp_by_model(input_path, target_path, score):\n",
    "    \"\"\"\n",
    "    input_path：输入视频图片目录\n",
    "    target_path：输出标记图片目录\n",
    "    score：模型参数\n",
    "    \"\"\"\n",
    "    if not os.path.exists(target_path):\n",
    "        os.mkdir(target_path)\n",
    "\n",
    "    # 初始化模型\n",
    "    yolo = YOLO(model_path=model_path, anchors_path=anchors_path, classes_path=classes_path,\n",
    "               score=score, iou=iou, model_image_size=model_image_size, gpu_num=gpu_num)\n",
    "\n",
    "    # 模型预测\n",
    "    results = []\n",
    "    img_names = get_dir_sorted_imgs(input_path)\n",
    "    for filename in img_names:\n",
    "        img_path = os.path.join(input_path, filename)\n",
    "        pred_results, image, c = yolo.predict_file(img_path, target_path, draw_rect=True, cut=False, \n",
    "                                                         one_box=True, timing=False, expand=1)\n",
    "        if len(pred_results) == 1:\n",
    "            #results.append('%s,%s,%s,%s,%s,%s,%s\\n' % (filename, 1, pred_results[0][4], pred_results[0][0], pred_results[0][1],pred_results[0][2], pred_results[0][3]))\n",
    "            results.append((filename, 1))\n",
    "        else:\n",
    "            results.append((filename, 0))\n",
    "\n",
    "    return results\n",
    "\n",
    "# 息肉统计结果写入文件\n",
    "def write_stat_result(output_file, video_name, score, poly_results, video_len, fps):\n",
    "    # 息肉个数\n",
    "    r = stat_ct(poly_results)\n",
    "    r = merge_ct(r)\n",
    "#     r = filt_polyp(r)\n",
    "    poly_num = len(r)\n",
    "    \n",
    "    with open(output_file, 'a+') as f:\n",
    "    # 写息肉出现时间点\n",
    "        for rr in r:\n",
    "            f.write('%.3f\t%d\t%d\\n' % (rr[0] / fps, rr[0], rr[1]))\n",
    "    \n",
    "    # 写息肉个数和视频长度比\n",
    "        f.write('%s\t%.3f\t%.3f\\n' % (video_name, score, poly_num/video_len))\n",
    "        \n",
    "    return poly_num/video_len\n",
    "        \n",
    "# 根据视频图片数量统计视频长度\n",
    "def get_video_len(video_imgs_dir, fps):\n",
    "    imgs = list(os.listdir(video_imgs_dir))\n",
    "    return len(imgs) / (fps * 60)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0fbd79",
   "metadata": {},
   "source": [
    "### 挑选真息肉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ddb58e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 1149\n",
      "processing: 1162\n",
      "processing: 1202\n",
      "processing: 2161\n",
      "processing: 1354\n",
      "processing: 2154\n",
      "processing: 1307\n",
      "processing: 1293\n",
      "processing: 1435\n",
      "processing: 2003\n",
      "processing: 2156\n",
      "processing: 2195\n",
      "processing: 3513\n",
      "processing: 1014\n",
      "processing: 3538\n",
      "processing: 1447\n",
      "processing: 2135\n",
      "processing: 2230\n",
      "processing: 3479\n",
      "processing: 3497\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "base_dir = r'D:\\项目资料\\息肉假阳性\\20221103'\n",
    "from_path = os.path.join(base_dir, 'images_crop')\n",
    "to_path = os.path.join(base_dir, 'images_truepoly_crop')\n",
    "\n",
    "folder_imgs = [(1149, [(5187, 5740), (6568, 6702)]), (1162, [(1970, 2107), (3923, 4100)]), (1202, [(339, 1036), (4278, 4444)]), \n",
    "               (2161, [(912, 996), (2707, 2867), (9939, 10467)]), (1354, [(1633, 2172), (3719, 3847)]),\n",
    "               (2154, [(2048, 2074), (5192, 5534)]), \n",
    "                (1307, [(1131, 1183)]), (1293, [(1303, 1470)]), (1435, [(5616, 5707)]), (2003, [(4532, 4715)]), \n",
    "                (2156, [(1254, 1341), (5450, 5872)]), (2195, [(3282, 3664), (4070, 4150), (4718, 4897), (6249, 6354)]), \n",
    "               (3513, [(2092, 3350), (4077, 4248)]), (1014, [(5115, 5160), (5591, 5681)]),\n",
    "                (3538, [(5630, 5721)]), (1447, [(4743, 4879)]), (2135, [(5692, 5782)]), \n",
    "               (2230, [(4042, 4153), (4943, 5075), (5095, 5266)]), (3479, [(4690, 4734), (7254, 7987)]),\n",
    "                (3497, [(1517, 2914), (5764, 5790)])]\n",
    "\n",
    "for folder, start_ends in folder_imgs:\n",
    "    from_folder = os.path.join(from_path, str(folder))\n",
    "    to_folder = os.path.join(to_path, str(folder))\n",
    "    print('processing: %s' % folder)\n",
    "    if not os.path.exists(to_folder):\n",
    "        os.mkdir(to_folder)\n",
    "        \n",
    "    for start, end in start_ends:\n",
    "        for i in range(start, end+1):\n",
    "            img_name = '%s.jpg' % i\n",
    "            from_img = os.path.join(from_folder, img_name)\n",
    "            shutil.copy(from_img, os.path.join(to_folder, img_name))\n",
    "            if os.path.exists(from_img):\n",
    "                os.remove(from_img)\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ec54d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [(106, 474), (3211, 3294)]\n",
    "a[0][1] - a[0][0] + a[1][1] - a[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c37e8c",
   "metadata": {},
   "source": [
    "### 运行息肉检测部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91b77c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 16:14:16,839 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3442 0.002\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 16:28:33,727 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.50167117618972\n",
      "2195 0.8\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 16:38:48,281 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.872849796063132\n",
      "3497 0.003\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n",
      "15.02692998204668\n"
     ]
    }
   ],
   "source": [
    "fps = 18\n",
    "# score = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35]\n",
    "base_dir = r'D:\\项目资料\\息肉假阳性\\20221103'\n",
    "\n",
    "## 假阳性检测\n",
    "video_names_score=[\n",
    "#                     ('3419', 0.2),  # 0-5 -> 1.12\n",
    "#                     ('3429', 0.2),  # 0-5 -> 4.14\n",
    "#                     ('3434', 0.2),  # 0-5 -> 2.24\n",
    "#                     ('3435', 0.001), # 15-20 -> 19.11\n",
    "#                     ('3438', 0.005), # 15-20 -> 15.86\n",
    "#                     ('3442', 0.002), # 15-20 -> 16.5\n",
    "#                     ('1149', 0.08),  # 5-10  -> 8.62\n",
    "#                     ('1162', 0.05),  # 5-10 -> 5.18\n",
    "#                     ('1202', 0.05),  # 5-10 -> 7.41\n",
    "#                     ('2161', 0.015),  # 10-15 -> 13.17\n",
    "#                     ('1354', 0.02),  # 10-15 -> 13.02\n",
    "#                     ('2154', 0.02),  # 10-15 -> 13.43\n",
    "#                     ('1307', 0.4), # 0-5 -> 3.58\n",
    "#                     ('1293', 0.2), # 0-5 -> 3.39\n",
    "#                     ('1435', 0.5), # 0-5 -> 4.19\n",
    "#                     ('2003', 0.2), # 0-5 -> 4.95\n",
    "#                     ('2156', 0.2), # 0-5 -> 3.04\n",
    "#                     ('2195', 0.8), # 0-5 -> 2.87\n",
    "#                     ('3513', 0.2), # 0-5 -> 2.76\n",
    "#                     ('1014', 0.008), # 15-20 -> 18.32\n",
    "#                     ('3538', 0.002), # 15-20 -> 18.9\n",
    "#                     ('1447', 0.007), # 15-20 -> 17.56\n",
    "#                     ('2135', 0.007), # 15-20 -> 19.16\n",
    "#                     ('2230', 0.005), # 15-20 -> 19.28\n",
    "#                     ('3479', 0.005), # 15-20 -> 18.73\n",
    "#                     ('3497', 0.003), # 15-20 -> 15.0\n",
    "]\n",
    "\n",
    "# video_names_score=[('1006', 0.015)] # 0.03：8.84, 0.015: 13.95\n",
    "\n",
    "input_base_dir = os.path.join(base_dir, 'images_crop')\n",
    "output_base_dir = os.path.join(base_dir, 'images_detect')\n",
    "for video_name, score in video_names_score:\n",
    "    print(video_name, score)\n",
    "    poly_results = detect_polyp_by_model(os.path.join(input_base_dir, video_name), \n",
    "                                         os.path.join(output_base_dir, '%s_%s' % (video_name, score)), score)\n",
    "    val = write_stat_result(os.path.join(base_dir, 'stat.txt'), video_name, score, poly_results,\n",
    "                      get_video_len(os.path.join(input_base_dir, video_name), fps), fps)\n",
    "    print(val)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f6339ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:37:26,910 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:37:47,822 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1149 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:39:36,361 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1162 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:40:26,189 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:42:30,287 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1293 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:42:56,506 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1307 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:43:05,976 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1354 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:44:40,947 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1435 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:44:56,043 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1447 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:45:15,981 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:45:44,910 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2135 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:45:59,444 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2154 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:46:54,882 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2156 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:48:09,418 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2161 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:50:02,328 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2195 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:51:56,286 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2230 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:52:57,829 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3479 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:54:52,089 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3497 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 01:58:10,334 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3513 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 02:01:32,484 - INFO - yolo.py - generate - 132 - load yolo model D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3538 0.001\n",
      "<class 'keras.engine.functional.Functional'> 111111111\n",
      "D:\\projects\\Vision\\polyp\\Models\\trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    }
   ],
   "source": [
    "## 真阳性检测\n",
    "true_poly_score = 0.001\n",
    "input_base_dir = os.path.join(base_dir, 'images_truepoly_crop')\n",
    "output_base_dir = os.path.join(base_dir, 'images_truepoly_detect')\n",
    "for video_name in os.listdir(input_base_dir):\n",
    "    score = true_poly_score\n",
    "    print(video_name, score)\n",
    "    poly_results = detect_polyp_by_model(os.path.join(input_base_dir, video_name), \n",
    "                                         os.path.join(output_base_dir, '%s_%s' % (video_name, score)), score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150cf513",
   "metadata": {},
   "source": [
    "### 运行真息肉标记\n",
    "暂时不用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a734f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_base_dir = os.path.join(base_dir, 'images_crop')\n",
    "output_base_dir = os.path.join(base_dir, 'images_detect')\n",
    "\n",
    "# 找到文件夹对应的score后缀\n",
    "folder_score = {}\n",
    "for folder in os.listdir(output_base_dir):\n",
    "    arr = folder.split('_')\n",
    "    folder_score[arr[0]] = arr[1]\n",
    "    \n",
    "for folder, score in folder_score.items():\n",
    "    if folder != '3531':\n",
    "        continue\n",
    "    print(folder, score)\n",
    "    results = []\n",
    "    img_names = get_dir_sorted_imgs(os.path.join(input_base_dir, folder))\n",
    "    det_img_names = set(get_dir_sorted_imgs(os.path.join(output_base_dir, '%s_%s' % (folder, score))))\n",
    "    for img_name in img_names:\n",
    "        if img_name not in det_img_names:\n",
    "            results.append((img_name, 0))\n",
    "        else:\n",
    "            results.append((img_name, 1))\n",
    "            \n",
    "    val = write_stat_result(os.path.join(base_dir, 'stat.txt'), folder, float(score), results,\n",
    "                      get_video_len(os.path.join(input_base_dir, folder), fps), fps)\n",
    "    print(val)\n",
    "    \n",
    "\n",
    "## 假阳性设置score\n",
    "# for video_name, score in [\n",
    "#     ('3429', 0.008)\n",
    "# ]:\n",
    "## 真阳性检测\n",
    "# for video_name in os.listdir(input_base_dir):\n",
    "#     score = true_poly_score\n",
    "    \n",
    "#     print(video_name, score)\n",
    "#     poly_results = detect_polyp_by_model(os.path.join(input_base_dir, video_name), \n",
    "#                                          os.path.join(output_base_dir, '%s_%s' % (video_name, score)), score)\n",
    "#     val = write_stat_result(os.path.join(base_dir, 'stat.txt'), video_name, score, poly_results,\n",
    "#                       get_video_len(os.path.join(input_base_dir, video_name), fps), fps)\n",
    "#     print(val)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 运行记录\n",
    "3400 0.01 12.839\n",
    "3400 0.35 3.959"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747bdcb2",
   "metadata": {},
   "source": [
    "### 合成视频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aa305b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "fps = 18\n",
    "\n",
    "# 将生成的息肉图片和原始图片一起合成息肉标记视频\n",
    "def create_mp4(raw_img_paths, fake_polyp_path, true_polyp_path, output_video_path):\n",
    "    \n",
    "    image = cv2.imdecode(np.fromfile(os.path.join(raw_img_paths[0], os.listdir(raw_img_paths[0])[0]), dtype=np.uint8), -1)\n",
    "    img_h, img_w, _ = image.shape\n",
    "\n",
    "    video_path = output_video_path\n",
    "    video = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*\"XVID\"), fps, (img_w, img_h))\n",
    "    \n",
    "    img_names = get_dir_sorted_imgs(raw_img_paths)\n",
    "    for f in img_names:\n",
    "        filepath11 = os.path.join(raw_img_paths[0], f)\n",
    "        filepath12 = os.path.join(raw_img_paths[1], f)\n",
    "        filepath2 = os.path.join(fake_polyp_path, f)\n",
    "        filepath3 = os.path.join(true_polyp_path, f)\n",
    "        if os.path.exists(filepath3):\n",
    "            filepath = filepath3\n",
    "        elif os.path.exists(filepath2):\n",
    "            filepath = filepath2\n",
    "        elif os.path.exists(filepath11):\n",
    "            filepath = filepath11\n",
    "        elif os.path.exists(filepath12):\n",
    "            filepath = filepath12\n",
    "        image = cv2.imdecode(np.fromfile(filepath, dtype=np.uint8),-1)\n",
    "        video.write(image)\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fc69088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 1014\n",
      "processing: 1149\n",
      "processing: 1162\n",
      "processing: 1202\n",
      "processing: 1293\n",
      "processing: 1307\n",
      "processing: 1354\n",
      "processing: 1435\n",
      "processing: 1447\n",
      "processing: 2003\n",
      "processing: 2135\n",
      "processing: 2154\n",
      "processing: 2156\n",
      "processing: 2161\n",
      "processing: 2195\n",
      "processing: 2230\n",
      "processing: 3419\n",
      "processing: 3429\n",
      "processing: 3434\n",
      "processing: 3435\n",
      "processing: 3438\n",
      "processing: 3442\n",
      "processing: 3479\n",
      "processing: 3497\n",
      "processing: 3513\n",
      "processing: 3538\n"
     ]
    }
   ],
   "source": [
    "## 无辅助视频合成\n",
    "for base_dir in [r'D:\\项目资料\\息肉假阳性\\20221007']:\n",
    "    raw_img_folders = [os.path.join(base_dir, '..', '20221103', 'images_crop'), os.path.join(base_dir, '..', '20221103', 'images_truepoly_crop')]\n",
    "    fake_polyp_folder = os.path.join(base_dir, 'images_detect_wfz')\n",
    "    true_polyp_folder = os.path.join(base_dir, 'images_truepoly_detect_wfz')\n",
    "    output_video_folder = os.path.join(base_dir, 'videos_gen_wfz')\n",
    "    \n",
    "    # 循环处理\n",
    "    for video_name in os.listdir(os.path.join(base_dir, '..', '20221103', 'images')):\n",
    "        print('processing: %s' % (video_name))\n",
    "        raw_img_paths = [os.path.join(rf, video_name) for rf in raw_img_folders]\n",
    "        fake_polyp_path = os.path.join(fake_polyp_folder, '%s' % (video_name))\n",
    "        true_polyp_path = os.path.join(true_polyp_folder, '%s' % (video_name))\n",
    "        output_video_path = os.path.join(output_video_folder, r'%s.avi' % (video_name))\n",
    "\n",
    "        create_mp4(raw_img_paths, fake_polyp_path, true_polyp_path, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aa346bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 1014, 0.008\n",
      "processing: 1149, 0.08\n",
      "processing: 1162, 0.05\n",
      "processing: 1202, 0.05\n",
      "processing: 1293, 0.2\n",
      "processing: 1307, 0.4\n",
      "processing: 1354, 0.02\n",
      "processing: 1435, 0.5\n",
      "processing: 1447, 0.007\n",
      "processing: 2003, 0.2\n",
      "processing: 2135, 0.007\n",
      "processing: 2154, 0.02\n",
      "processing: 2156, 0.2\n",
      "processing: 2161, 0.015\n",
      "processing: 2195, 0.8\n",
      "processing: 2230, 0.005\n",
      "processing: 3419, 0.2\n",
      "processing: 3429, 0.2\n",
      "processing: 3434, 0.2\n",
      "processing: 3435, 0.001\n",
      "processing: 3438, 0.005\n",
      "processing: 3442, 0.002\n",
      "processing: 3479, 0.005\n",
      "processing: 3497, 0.003\n",
      "processing: 3513, 0.2\n",
      "processing: 3538, 0.002\n"
     ]
    }
   ],
   "source": [
    "for base_dir in [r'D:\\项目资料\\息肉假阳性\\20221103']:\n",
    "    raw_img_folders = [os.path.join(base_dir, 'images_crop'), os.path.join(base_dir, 'images_truepoly_crop')]\n",
    "    fake_polyp_folder = os.path.join(base_dir, 'images_detect')\n",
    "    true_polyp_folder = os.path.join(base_dir, 'images_truepoly_detect')\n",
    "    output_video_folder = os.path.join(base_dir, 'videos_gen')\n",
    "    \n",
    "    # 文件夹名和分数\n",
    "#     video_names = os.listdir(raw_img_folder)\n",
    "#     folder_score = {video_name: '' for video_name in video_names}\n",
    "    folder_score_arr = []\n",
    "    for folder in os.listdir(fake_polyp_folder):\n",
    "        arr = folder.split('_')\n",
    "        folder_score_arr.append((arr[0], arr[1]))\n",
    "    \n",
    "    # 循环处理\n",
    "    for video_name, score in folder_score_arr:\n",
    "        print('processing: %s, %s' % (video_name, score))\n",
    "        raw_img_paths = [os.path.join(rf, video_name) for rf in raw_img_folders]\n",
    "        fake_polyp_path = os.path.join(fake_polyp_folder, '%s_%s' % (video_name, score))\n",
    "        true_polyp_path = os.path.join(true_polyp_folder, '%s_%s' % (video_name, 0.001))\n",
    "        output_video_path = os.path.join(output_video_folder, r'%s_%s.avi' % (video_name, score))\n",
    "\n",
    "        create_mp4(raw_img_paths, fake_polyp_path, true_polyp_path, output_video_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c8ea1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

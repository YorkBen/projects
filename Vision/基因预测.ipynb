{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64608f6f",
   "metadata": {},
   "source": [
    "### 从所有的基因数据中选取需要处理的500多个的子集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "104e22c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基因字典，筛选出的基因： 537 537\n",
      "306\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import Workbook\n",
    "import os\n",
    "\n",
    "csv_all = r'D:\\项目资料\\基因表达\\数据\\TCGA-COAD.htseq_counts.tsv'\n",
    "csv_select = r'D:\\项目资料\\基因表达\\数据\\Diff_genes_name.csv'\n",
    "xlsx_out = r'genes.xlsx'\n",
    "pic_data = r'E:\\DX-color-result0702\\train'\n",
    "name_length = 12\n",
    "\n",
    "# 500多个基因\n",
    "gene_dict = {}\n",
    "with open(csv_select) as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        arr = line.strip().split(',')\n",
    "        gene_dict[arr[1]] = arr[2]\n",
    "\n",
    "# 输出文件\n",
    "wb = Workbook()\n",
    "sheet = wb.create_sheet('Sheet1')\n",
    "\n",
    "cols = []\n",
    "gene_data = {}\n",
    "with open(csv_all) as f:\n",
    "    for idx, line in enumerate(f.readlines()):\n",
    "        arr = line.strip().split('\\t')\n",
    "        if idx == 0:\n",
    "            for name in arr[1:]:\n",
    "                cols.append(name[:name_length])\n",
    "        else:\n",
    "            gene_id = arr[0].split('.')[0]\n",
    "            if gene_id in gene_dict:\n",
    "                gene_data[gene_id] = arr[1:]\n",
    "print('基因字典，筛选出的基因：', len(gene_dict), len(gene_data))\n",
    "    \n",
    "\n",
    "# 有数据的目录\n",
    "folders = []\n",
    "for folder1 in os.listdir(pic_data):\n",
    "    folder_path = os.path.join(pic_data, folder1)\n",
    "    for folder2 in os.listdir(folder_path):\n",
    "#         print(folder2[:16])\n",
    "        if folder2[:name_length] in cols:\n",
    "            folders.append(folder2)\n",
    "folders = set(folders)\n",
    "\n",
    "print(len(folders))\n",
    "\n",
    "    \n",
    "wb.save(xlsx_out)\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc8d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import keras\n",
    "from tensorflow.keras import layers, datasets\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f59a1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "  tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5dc429",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.resnet50.ResNet50(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(224, 224, 3)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb6f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_gen = ImageDataGenerator(fill_mode='nearest',\n",
    "                                   width_shift_range = 0.15,\n",
    "                                    height_shift_range = 0.15,\n",
    "                                    shear_range = 0,\n",
    "                                    rotation_range = 15,\n",
    "                                    zoom_range = 0.1,\n",
    "                                    vertical_flip=False,\n",
    "                                    horizontal_flip=False\n",
    "                                                 ,samplewise_center=True\n",
    "                                                 ,samplewise_std_normalization=True\n",
    "                                                ) \n",
    "\n",
    "val_img_gen = ImageDataGenerator(fill_mode='nearest'\n",
    "                                                 ,samplewise_center=True\n",
    "                                                 ,samplewise_std_normalization=True\n",
    "                                                ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e1ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_type, target_size, batch_size):\n",
    "    # data path\n",
    "    train_data_path = r'D:\\项目资料\\基因表达\\数据'\n",
    "    val_data_path = r'D:\\项目资料\\基因表达\\数据'\n",
    "    test_data_path = r'D:\\项目资料\\基因表达\\数据'\n",
    "    \n",
    "    train_gen = train_img_gen.flow_from_directory(train_data_path,\n",
    "                                    target_size = target_size,\n",
    "                                    color_mode = 'rgb',\n",
    "#                                     classes = [''],\n",
    "                                    class_mode = 'categorical',\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = True,\n",
    "                                    seed = None,\n",
    "                                    interpolation = 'nearest',\n",
    "                                    keep_aspect_ratio=False\n",
    "                                                 )\n",
    "    print('Train data loaded: total: %s, batch size: %s, num classes: %s\\n' % (train_gen.n, train_gen.batch_size, train_gen.num_classes))\n",
    "    \n",
    "    val_gen = val_img_gen.flow_from_directory(val_data_path,\n",
    "                                    target_size = target_size,\n",
    "                                    color_mode = 'rgb',\n",
    "#                                     classes = [''],\n",
    "                                    class_mode = 'categorical',\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = False,\n",
    "                                    seed = None,\n",
    "                                    interpolation = 'nearest',\n",
    "                                    keep_aspect_ratio=False\n",
    "                                             )\n",
    "    print('Val data loaded: total: %s, batch size: %s, num classes: %s\\n' % (val_gen.n, val_gen.batch_size, val_gen.num_classes))\n",
    "    \n",
    "    return train_gen, val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(type='Mobilenet', num_classes=27):\n",
    "#     scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "\n",
    "    base_model, input_shape = get_base_model(type), get_basemodel_shape(type)\n",
    "    base_model.trainable = False\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # 模型定义\n",
    "#     x = scale_layer(inputs)\n",
    "    x = inputs\n",
    "    x = base_model(x, training=False)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)  # Regularize with dropout\n",
    "    x = tf.keras.layers.Dense(num_classes)(x)\n",
    "#     outputs = tf.keras.layers.Softmax()(x)\n",
    "    outputs = x\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39fd1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch > 2:\n",
    "        lr = lr * tf.math.exp(-0.051)\n",
    "    return lr\n",
    "    \n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "scheduler_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "def get_callbacks(modl_type, data_type, unfrozen_layers=None):\n",
    "    model_checkpoint = ModelCheckpoint(get_mdl_name(data_type, modl_type, unfrozen_layers), monitor='val_accuracy', verbose=2, save_best_only=True)\n",
    "    callbacks = [early_stop, model_checkpoint, scheduler_callback]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9388d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler(21, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56cf5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "modl_types = ['VGG16', 'ResNet50', 'EfficientNet-B4']\n",
    "data_types = ['esophagus_28', 'pharynx_5']\n",
    "batch_sizes = 4, 32\n",
    "def transfer_learning(mdl_idx, data_idx, init_lr=1e-2, epochs=5, batch_size=64):\n",
    "    modl_type = modl_types[mdl_idx]\n",
    "    img_shape = get_basemodel_shape(modl_type)[:2]\n",
    "    data_type = data_types[data_idx]\n",
    "    BATCH_SIZE = batch_size\n",
    "    \n",
    "    # 参数\n",
    "    num_clses = int(data_type.split('_')[1])\n",
    "\n",
    "    # 定义模型\n",
    "    model = build_model(type=modl_type, num_classes=num_clses)\n",
    "    model.compile(optimizer = Adam(learning_rate = init_lr), \n",
    "                      loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "    # 加载数据\n",
    "    train_gen, val_gen = load_data(data_type, img_shape, BATCH_SIZE)\n",
    "\n",
    "\n",
    "    # 训练\n",
    "    history = model.fit(train_gen, steps_per_epoch=train_gen.n // BATCH_SIZE, epochs=epochs,\n",
    "                        validation_data=val_gen, validation_steps=val_gen.n // BATCH_SIZE,\n",
    "                        callbacks=get_callbacks(modl_type, data_type), workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(mdl_idx, data_idx, chpkt_path, init_lr=1e-5, unfrozen_layers=-200, epochs=5, batch_size=16):\n",
    "    modl_type = modl_types[mdl_idx]\n",
    "    img_shape = get_basemodel_shape(modl_type)[:2]\n",
    "    data_type = data_types[data_idx]\n",
    "    BATCH_SIZE = batch_size\n",
    "    \n",
    "    # 参数\n",
    "    num_clses = int(data_type.split('_')[1])\n",
    "    \n",
    "    # 定义模型\n",
    "    model = tf.keras.models.load_model(chpkt_path)\n",
    "#     model.trainable = True\n",
    "    print(len(model.layers[1].layers))\n",
    "    for layer in model.layers[1].layers[unfrozen_layers:]:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "            \n",
    "    model.compile(optimizer = Adam(learning_rate = init_lr), \n",
    "                          loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                          metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    # 加载数据\n",
    "    train_gen, val_gen = load_data(data_type, img_shape, BATCH_SIZE)\n",
    "\n",
    "\n",
    "    # 训练\n",
    "    history = model.fit(train_gen, steps_per_epoch=train_gen.n // BATCH_SIZE, epochs=epochs,\n",
    "                        validation_data=val_gen, validation_steps=val_gen.n // BATCH_SIZE,\n",
    "                        callbacks=get_callbacks(modl_type, data_type, unfrozen_layers), workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b326ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_idx, data_idx = 2, 0\n",
    "# transfer_learning(mdl_idx, data_idx, 1e-2, 3, 16)\n",
    "# finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx), 1e-5, 120, 50, 4)\n",
    "finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx), 1e-6, 120, 20, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

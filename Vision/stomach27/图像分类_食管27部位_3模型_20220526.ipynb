{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0f163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import keras\n",
    "from tensorflow.keras import layers, datasets\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb6f2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "  tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c25e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basemodel_shape(type):\n",
    "    if type == 'EfficientNet-B4':\n",
    "        return (380, 380, 3)\n",
    "#         return (224, 224, 3)\n",
    "    elif type == 'VGG16':\n",
    "        return (224, 224, 3)\n",
    "    elif type == 'ResNet50':\n",
    "        return (224, 224, 3)\n",
    "\n",
    "def get_base_model(type='Mobilenet'):\n",
    "    if type == 'EfficientNet-B4':\n",
    "        base_model = tf.keras.applications.efficientnet.EfficientNetB4(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=get_basemodel_shape(type)\n",
    "        )\n",
    "    elif type == 'VGG16':\n",
    "        base_model = tf.keras.applications.vgg16.VGG16(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=get_basemodel_shape(type)\n",
    "        )\n",
    "    elif type == 'ResNet50':\n",
    "        base_model = tf.keras.applications.resnet50.ResNet50(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=get_basemodel_shape(type)\n",
    "        )\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f33f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache path\n",
    "cache_path = r'D:\\projects\\Vision\\ckpts'\n",
    "if not os.path.exists(cache_path):\n",
    "    os.mkdir(cache_path)\n",
    "    \n",
    "def get_mdl_name(data_type, modl_type, unfrozen_layers):\n",
    "    if unfrozen_layers is not None:\n",
    "        save_path = os.path.join(r'D:\\projects\\Vision\\ckpts', r'%s_%s_%s' % (data_type, modl_type, unfrozen_layers))\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "    else:\n",
    "        save_path = cache_path\n",
    "    \n",
    "    mdl_save_name = data_type + '_' + modl_type + '_' + \\\n",
    "                time.strftime(\"%Y%m%d\", time.localtime(time.time())) + '_{epoch:02d}-{val_accuracy:.3f}.hdf5'\n",
    "    abs_model_name = os.path.join(save_path, mdl_save_name)\n",
    "    \n",
    "    return abs_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ac276a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_gen = ImageDataGenerator(fill_mode='nearest',\n",
    "                                   width_shift_range = 0.15,\n",
    "                                    height_shift_range = 0.15,\n",
    "                                    shear_range = 0,\n",
    "                                    rotation_range = 15,\n",
    "                                    zoom_range = 0.1,\n",
    "                                    vertical_flip=False,\n",
    "                                    horizontal_flip=False\n",
    "                                                 ,samplewise_center=True\n",
    "                                                 ,samplewise_std_normalization=True\n",
    "                                                ) \n",
    "\n",
    "val_img_gen = ImageDataGenerator(fill_mode='nearest'\n",
    "                                                 ,samplewise_center=True\n",
    "                                                 ,samplewise_std_normalization=True\n",
    "                                                ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89aee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_type, target_size, batch_size):\n",
    "    # data path\n",
    "    if data_type == 'esophagus_28':\n",
    "        train_data_path = r'\\\\192.168.0.154\\数据\\口咽部\\大部位27分类\\res_train_2'\n",
    "        val_data_path = r'\\\\192.168.0.154\\数据\\口咽部\\大部位27分类\\res_val'\n",
    "        test_data_path = r'\\\\192.168.0.154\\数据\\口咽部\\大部位27分类\\res_test'\n",
    "    else:\n",
    "        train_data_path = r'\\\\192.168.0.154\\数据\\口咽部\\第8轮\\res_train'\n",
    "        val_data_path = r'\\\\192.168.0.154\\数据\\口咽部\\第8轮\\res_val'\n",
    "        test_data_path = r'\\\\192.168.0.154\\数据\\口咽部\\第8轮\\res_test'\n",
    "    #     test_data_path = '\\\\192.168.0.154\\数据\\口咽部\\第8轮\\valid_date_结果\\富士'\n",
    "    \n",
    "    train_gen = train_img_gen.flow_from_directory(train_data_path,\n",
    "                                    target_size = target_size,\n",
    "                                    color_mode = 'rgb',\n",
    "#                                     classes = [''],\n",
    "                                    class_mode = 'categorical',\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = True,\n",
    "                                    seed = None,\n",
    "                                    interpolation = 'nearest',\n",
    "                                    keep_aspect_ratio=False\n",
    "                                                 )\n",
    "    print('Train data loaded: total: %s, batch size: %s, num classes: %s\\n' % (train_gen.n, train_gen.batch_size, train_gen.num_classes))\n",
    "    \n",
    "    val_gen = val_img_gen.flow_from_directory(val_data_path,\n",
    "                                    target_size = target_size,\n",
    "                                    color_mode = 'rgb',\n",
    "#                                     classes = [''],\n",
    "                                    class_mode = 'categorical',\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = False,\n",
    "                                    seed = None,\n",
    "                                    interpolation = 'nearest',\n",
    "                                    keep_aspect_ratio=False\n",
    "                                             )\n",
    "    print('Val data loaded: total: %s, batch size: %s, num classes: %s\\n' % (val_gen.n, val_gen.batch_size, val_gen.num_classes))\n",
    "    \n",
    "    return train_gen, val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d042589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(type='Mobilenet', num_classes=27):\n",
    "#     scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "\n",
    "    base_model, input_shape = get_base_model(type), get_basemodel_shape(type)\n",
    "    base_model.trainable = False\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # 模型定义\n",
    "#     x = scale_layer(inputs)\n",
    "    x = inputs\n",
    "    x = base_model(x, training=False)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)  # Regularize with dropout\n",
    "    x = tf.keras.layers.Dense(num_classes)(x)\n",
    "#     outputs = tf.keras.layers.Softmax()(x)\n",
    "    outputs = x\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98d04cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scheduler(epoch, lr):\n",
    "#     epoch = tf.cast(tf.math.add(epoch, 0), tf.float32)\n",
    "#     if epoch > 10:\n",
    "#         n_10 = tf.math.floordiv(epoch, 10)\n",
    "#         n_10_m = tf.math.multiply(n_10, 10)\n",
    "#         n_10_s = tf.math.subtract(epoch, n_10_m)\n",
    "#         if n_10_s == 0:\n",
    "#             lr = tf.math.multiply(tf.math.pow(0.1, n_10), 0.01)\n",
    "#         else:\n",
    "#             lr = lr * tf.math.exp(-0.1)\n",
    "#     return lr\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch > 2:\n",
    "        lr = lr * tf.math.exp(-0.051)\n",
    "    return lr\n",
    "    \n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "scheduler_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "def get_callbacks(modl_type, data_type, unfrozen_layers=None):\n",
    "    model_checkpoint = ModelCheckpoint(get_mdl_name(data_type, modl_type, unfrozen_layers), monitor='val_accuracy', verbose=2, save_best_only=True)\n",
    "    callbacks = [early_stop, model_checkpoint, scheduler_callback]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5783f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.009502786>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler(21, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ed40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modl_types = ['VGG16', 'ResNet50', 'EfficientNet-B4']\n",
    "data_types = ['esophagus_28', 'pharynx_5']\n",
    "batch_sizes = 4, 32\n",
    "def transfer_learning(mdl_idx, data_idx, init_lr=1e-2, epochs=5, batch_size=64):\n",
    "    modl_type = modl_types[mdl_idx]\n",
    "    img_shape = get_basemodel_shape(modl_type)[:2]\n",
    "    data_type = data_types[data_idx]\n",
    "    BATCH_SIZE = batch_size\n",
    "    \n",
    "    # 参数\n",
    "    num_clses = int(data_type.split('_')[1])\n",
    "\n",
    "    # 定义模型\n",
    "    model = build_model(type=modl_type, num_classes=num_clses)\n",
    "    model.compile(optimizer = Adam(learning_rate = init_lr), \n",
    "                      loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "    # 加载数据\n",
    "    train_gen, val_gen = load_data(data_type, img_shape, BATCH_SIZE)\n",
    "\n",
    "\n",
    "    # 训练\n",
    "    history = model.fit(train_gen, steps_per_epoch=train_gen.n // BATCH_SIZE, epochs=epochs,\n",
    "                        validation_data=val_gen, validation_steps=val_gen.n // BATCH_SIZE,\n",
    "                        callbacks=get_callbacks(modl_type, data_type), workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ef16d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(mdl_idx, data_idx, chpkt_path, init_lr=1e-5, unfrozen_layers=-200, epochs=5, batch_size=16):\n",
    "    modl_type = modl_types[mdl_idx]\n",
    "    img_shape = get_basemodel_shape(modl_type)[:2]\n",
    "    data_type = data_types[data_idx]\n",
    "    BATCH_SIZE = batch_size\n",
    "    \n",
    "    # 参数\n",
    "    num_clses = int(data_type.split('_')[1])\n",
    "    \n",
    "    # 定义模型\n",
    "    model = tf.keras.models.load_model(chpkt_path)\n",
    "#     model.trainable = True\n",
    "    print(len(model.layers[1].layers))\n",
    "    for layer in model.layers[1].layers[unfrozen_layers:]:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "            \n",
    "    model.compile(optimizer = Adam(learning_rate = init_lr), \n",
    "                          loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                          metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    # 加载数据\n",
    "    train_gen, val_gen = load_data(data_type, img_shape, BATCH_SIZE)\n",
    "\n",
    "\n",
    "    # 训练\n",
    "    history = model.fit(train_gen, steps_per_epoch=train_gen.n // BATCH_SIZE, epochs=epochs,\n",
    "                        validation_data=val_gen, validation_steps=val_gen.n // BATCH_SIZE,\n",
    "                        callbacks=get_callbacks(modl_type, data_type, unfrozen_layers), workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c68faa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_chkpt(mdl_idx, data_idx, unfrozen_layers):\n",
    "    modl_type = modl_types[mdl_idx]\n",
    "    data_type = data_types[data_idx]\n",
    "    header = data_type + '_' + modl_type\n",
    "    \n",
    "    results = []\n",
    "    if unfrozen_layers is not None:\n",
    "        mdl_dir = os.path.join(cache_path, '%s_%s_%s' % (data_type, modl_type, unfrozen_layers))\n",
    "        if os.path.exists(mdl_dir):\n",
    "            for f in os.listdir(mdl_dir):\n",
    "                if f.startswith(header):\n",
    "                    acc = float(f.split('-')[-1][:-5]) * 1000\n",
    "                    results.append((acc, os.path.join(mdl_dir, f)))\n",
    "            results = sorted(results, key=lambda x: x[0])\n",
    "            if len(results) > 0:\n",
    "                print('Best ckpt Selected: %s' % results[-1][1])\n",
    "                return results[-1][1]\n",
    "    \n",
    "    # ckpts文件夹找最大值模型\n",
    "    for f in os.listdir(cache_path):\n",
    "        if os.path.isfile(os.path.join(cache_path, f)) and f.startswith(header):\n",
    "            print(f)\n",
    "            acc = float(f.split('-')[-1][:-5]) * 1000\n",
    "            results.append((acc, os.path.join(cache_path, f)))\n",
    "    results = sorted(results, key=lambda x: x[0])\n",
    "    \n",
    "    print('Best ckpt Selected: %s' % results[-1][1])\n",
    "    return results[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bc93933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(mdl_idx, data_idx):\n",
    "    transfer_learning(mdl_idx, data_idx, 1e-2, 3, 16)\n",
    "    finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx), 1e-5, -475, 50, 8)\n",
    "    finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx), 1e-6, -475, 20, 8)\n",
    "#     finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx), 1e-7, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ba10260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ckpt Selected: esophagus_28_EfficientNet-B4_20220601_240-0.891.hdf5\n",
      "475\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, 7, 7, 1792)       17673823  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1792)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                50204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,724,027\n",
      "Trainable params: 17,473,620\n",
      "Non-trainable params: 250,407\n",
      "_________________________________________________________________\n",
      "Found 70552 images belonging to 28 classes.\n",
      "Train data loaded: total: 70552, batch size: 4, num classes: 28\n",
      "\n",
      "Found 7395 images belonging to 28 classes.\n",
      "Val data loaded: total: 7395, batch size: 4, num classes: 28\n",
      "\n",
      "Epoch 1/20\n",
      "17638/17638 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9263\n",
      "Epoch 1: val_accuracy improved from -inf to 0.88758, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_20220608_01-0.888.hdf5\n",
      "17638/17638 [==============================] - 2612s 147ms/step - loss: 0.2063 - accuracy: 0.9263 - val_loss: 0.3503 - val_accuracy: 0.8876 - lr: 1.0000e-06\n",
      "Epoch 2/20\n",
      "17638/17638 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9270\n",
      "Epoch 2: val_accuracy did not improve from 0.88758\n",
      "17638/17638 [==============================] - 2690s 152ms/step - loss: 0.2016 - accuracy: 0.9270 - val_loss: 0.3471 - val_accuracy: 0.8873 - lr: 1.0000e-06\n",
      "Epoch 3/20\n",
      "17638/17638 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.9290\n",
      "Epoch 3: val_accuracy improved from 0.88758 to 0.88988, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_20220608_03-0.890.hdf5\n",
      "17638/17638 [==============================] - 4057s 230ms/step - loss: 0.1960 - accuracy: 0.9290 - val_loss: 0.3464 - val_accuracy: 0.8899 - lr: 1.0000e-06\n",
      "Epoch 4/20\n",
      "17638/17638 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9310\n",
      "Epoch 4: val_accuracy did not improve from 0.88988\n",
      "17638/17638 [==============================] - 3218s 182ms/step - loss: 0.1886 - accuracy: 0.9310 - val_loss: 0.3544 - val_accuracy: 0.8877 - lr: 9.5028e-07\n",
      "Epoch 5/20\n",
      "17638/17638 [==============================] - ETA: 0s - loss: 0.1797 - accuracy: 0.9355\n",
      "Epoch 5: val_accuracy did not improve from 0.88988\n",
      "17638/17638 [==============================] - 2628s 149ms/step - loss: 0.1797 - accuracy: 0.9355 - val_loss: 0.3687 - val_accuracy: 0.8879 - lr: 9.0303e-07\n",
      "Epoch 6/20\n",
      "17638/17638 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.9360\n",
      "Epoch 6: val_accuracy did not improve from 0.88988\n",
      "17638/17638 [==============================] - 2628s 149ms/step - loss: 0.1769 - accuracy: 0.9360 - val_loss: 0.3654 - val_accuracy: 0.8872 - lr: 8.5813e-07\n"
     ]
    }
   ],
   "source": [
    "mdl_idx, data_idx = 2, 0\n",
    "# transfer_learning(mdl_idx, data_idx, 1e-2, 3, 16)\n",
    "# finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx), 1e-5, 120, 50, 4)\n",
    "finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx), 1e-6, 120, 20, 4)\n",
    "\n",
    "# run(1, 1)\n",
    "# finetune(1, 1, find_best_chkpt(1, 1), 1e-7)\n",
    "# finetune(0, 1, r'D:\\projects\\Vision\\ckpts\\pharynx_5_VGG16_20220527_10-0.953.hdf5', 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa6c86e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ckpt Selected: esophagus_28_EfficientNet-B4_20220617_Finetune-0.241.hdf5\n",
      "475\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 380, 380, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, 12, 12, 1792)     17673823  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1792)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                50204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,724,027\n",
      "Trainable params: 11,732,808\n",
      "Non-trainable params: 5,991,219\n",
      "_________________________________________________________________\n",
      "Found 70719 images belonging to 28 classes.\n",
      "Train data loaded: total: 70719, batch size: 4, num classes: 28\n",
      "\n",
      "Found 7395 images belonging to 28 classes.\n",
      "Val data loaded: total: 7395, batch size: 4, num classes: 28\n",
      "\n",
      "Epoch 1/5\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 2.2365 - accuracy: 0.3355\n",
      "Epoch 1: val_accuracy improved from -inf to 0.48999, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_20220617_01-0.490.hdf5\n",
      "17679/17679 [==============================] - 1896s 107ms/step - loss: 2.2365 - accuracy: 0.3355 - val_loss: 1.6373 - val_accuracy: 0.4900 - lr: 1.0000e-05\n",
      "Epoch 2/5\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 1.7239 - accuracy: 0.4643\n",
      "Epoch 2: val_accuracy improved from 0.48999 to 0.57373, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_20220617_02-0.574.hdf5\n",
      "17679/17679 [==============================] - 1876s 106ms/step - loss: 1.7239 - accuracy: 0.4643 - val_loss: 1.3437 - val_accuracy: 0.5737 - lr: 1.0000e-05\n",
      "Epoch 3/5\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 1.4750 - accuracy: 0.5324\n",
      "Epoch 3: val_accuracy improved from 0.57373 to 0.61418, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_20220617_03-0.614.hdf5\n",
      "17679/17679 [==============================] - 1924s 109ms/step - loss: 1.4750 - accuracy: 0.5324 - val_loss: 1.2198 - val_accuracy: 0.6142 - lr: 1.0000e-05\n",
      "Epoch 4/5\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 1.3116 - accuracy: 0.5802\n",
      "Epoch 4: val_accuracy improved from 0.61418 to 0.66342, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_20220617_04-0.663.hdf5\n",
      "17679/17679 [==============================] - 1912s 108ms/step - loss: 1.3116 - accuracy: 0.5802 - val_loss: 1.0465 - val_accuracy: 0.6634 - lr: 9.5028e-06\n",
      "Epoch 5/5\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 1.1848 - accuracy: 0.6173\n",
      "Epoch 5: val_accuracy improved from 0.66342 to 0.67005, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_20220617_05-0.670.hdf5\n",
      "17679/17679 [==============================] - 1906s 108ms/step - loss: 1.1848 - accuracy: 0.6173 - val_loss: 1.0082 - val_accuracy: 0.6700 - lr: 9.0303e-06\n"
     ]
    }
   ],
   "source": [
    "mdl_idx, data_idx = 2, 0\n",
    "finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx), 1e-5, 360, 5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20b089c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ckpt Selected: D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_240\\esophagus_28_EfficientNet-B4_20220617_05-0.863.hdf5\n",
      "475\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 380, 380, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, 12, 12, 1792)     17673823  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1792)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                50204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,724,027\n",
      "Trainable params: 16,093,944\n",
      "Non-trainable params: 1,630,083\n",
      "_________________________________________________________________\n",
      "Found 70719 images belonging to 28 classes.\n",
      "Train data loaded: total: 70719, batch size: 4, num classes: 28\n",
      "\n",
      "Found 7395 images belonging to 28 classes.\n",
      "Val data loaded: total: 7395, batch size: 4, num classes: 28\n",
      "\n",
      "Epoch 1/20\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.8866\n",
      "Epoch 1: val_accuracy improved from -inf to 0.86350, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_240\\esophagus_28_EfficientNet-B4_20220620_01-0.864.hdf5\n",
      "17679/17679 [==============================] - 2254s 126ms/step - loss: 0.3233 - accuracy: 0.8866 - val_loss: 0.4412 - val_accuracy: 0.8635 - lr: 1.0000e-05\n",
      "Epoch 2/20\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.3016 - accuracy: 0.8936\n",
      "Epoch 2: val_accuracy did not improve from 0.86350\n",
      "17679/17679 [==============================] - 2248s 127ms/step - loss: 0.3016 - accuracy: 0.8936 - val_loss: 0.4317 - val_accuracy: 0.8627 - lr: 1.0000e-05\n",
      "Epoch 3/20\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.9022\n",
      "Epoch 3: val_accuracy did not improve from 0.86350\n",
      "17679/17679 [==============================] - 2237s 127ms/step - loss: 0.2763 - accuracy: 0.9022 - val_loss: 0.4580 - val_accuracy: 0.8588 - lr: 1.0000e-05\n",
      "Epoch 4/20\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.9114\n",
      "Epoch 4: val_accuracy did not improve from 0.86350\n",
      "17679/17679 [==============================] - 2229s 126ms/step - loss: 0.2474 - accuracy: 0.9114 - val_loss: 0.4796 - val_accuracy: 0.8600 - lr: 9.5028e-06\n"
     ]
    }
   ],
   "source": [
    "mdl_idx, data_idx, uf_layer = 2, 0, 240\n",
    "finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx, uf_layer), 1e-5, uf_layer, 20, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a345ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ckpt Selected: D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_240\\esophagus_28_EfficientNet-B4_20220620_01-0.864.hdf5\n",
      "475\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 380, 380, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, 12, 12, 1792)     17673823  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1792)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                50204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,724,027\n",
      "Trainable params: 16,093,944\n",
      "Non-trainable params: 1,630,083\n",
      "_________________________________________________________________\n",
      "Found 70719 images belonging to 28 classes.\n",
      "Train data loaded: total: 70719, batch size: 4, num classes: 28\n",
      "\n",
      "Found 7395 images belonging to 28 classes.\n",
      "Val data loaded: total: 7395, batch size: 4, num classes: 28\n",
      "\n",
      "Epoch 1/20\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2492 - accuracy: 0.9111\n",
      "Epoch 1: val_accuracy improved from -inf to 0.87284, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_240\\esophagus_28_EfficientNet-B4_20220620_01-0.873.hdf5\n",
      "17679/17679 [==============================] - 2240s 126ms/step - loss: 0.2492 - accuracy: 0.9111 - val_loss: 0.4202 - val_accuracy: 0.8728 - lr: 1.0000e-06\n",
      "Epoch 2/20\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.9184\n",
      "Epoch 2: val_accuracy improved from 0.87284 to 0.87419, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_240\\esophagus_28_EfficientNet-B4_20220620_02-0.874.hdf5\n",
      "17679/17679 [==============================] - 2217s 125ms/step - loss: 0.2291 - accuracy: 0.9184 - val_loss: 0.4292 - val_accuracy: 0.8742 - lr: 1.0000e-06\n",
      "Epoch 3/20\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2204 - accuracy: 0.9207\n",
      "Epoch 3: val_accuracy did not improve from 0.87419\n",
      "17679/17679 [==============================] - 2213s 125ms/step - loss: 0.2204 - accuracy: 0.9207 - val_loss: 0.4415 - val_accuracy: 0.8732 - lr: 1.0000e-06\n",
      "Epoch 4/20\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.9230\n",
      "Epoch 4: val_accuracy improved from 0.87419 to 0.87473, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_240\\esophagus_28_EfficientNet-B4_20220620_04-0.875.hdf5\n",
      "17679/17679 [==============================] - 2218s 125ms/step - loss: 0.2160 - accuracy: 0.9230 - val_loss: 0.4308 - val_accuracy: 0.8747 - lr: 9.5028e-07\n",
      "Epoch 5/20\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2080 - accuracy: 0.9254\n",
      "Epoch 5: val_accuracy improved from 0.87473 to 0.87568, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_240\\esophagus_28_EfficientNet-B4_20220620_05-0.876.hdf5\n",
      "17679/17679 [==============================] - 2213s 125ms/step - loss: 0.2080 - accuracy: 0.9254 - val_loss: 0.4466 - val_accuracy: 0.8757 - lr: 9.0303e-07\n",
      "Epoch 6/20\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.9267\n",
      "Epoch 6: val_accuracy did not improve from 0.87568\n",
      "17679/17679 [==============================] - 2220s 126ms/step - loss: 0.2030 - accuracy: 0.9267 - val_loss: 0.4481 - val_accuracy: 0.8738 - lr: 8.5813e-07\n",
      "Epoch 7/20\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.1991 - accuracy: 0.9284\n",
      "Epoch 7: val_accuracy did not improve from 0.87568\n",
      "17679/17679 [==============================] - 2228s 126ms/step - loss: 0.1991 - accuracy: 0.9284 - val_loss: 0.4408 - val_accuracy: 0.8741 - lr: 8.1546e-07\n",
      "Epoch 8/20\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.1958 - accuracy: 0.9298\n",
      "Epoch 8: val_accuracy did not improve from 0.87568\n",
      "17679/17679 [==============================] - 2240s 127ms/step - loss: 0.1958 - accuracy: 0.9298 - val_loss: 0.4674 - val_accuracy: 0.8724 - lr: 7.7492e-07\n"
     ]
    }
   ],
   "source": [
    "finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx, uf_layer), 1e-6, uf_layer, 20, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20cee7cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esophagus_28_EfficientNet-B4_20220617_TransferBase-0.241.hdf5\n",
      "Best ckpt Selected: D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_20220617_TransferBase-0.241.hdf5\n",
      "475\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 380, 380, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, 12, 12, 1792)     17673823  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1792)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                50204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,724,027\n",
      "Trainable params: 17,414,732\n",
      "Non-trainable params: 309,295\n",
      "_________________________________________________________________\n",
      "Found 70719 images belonging to 28 classes.\n",
      "Train data loaded: total: 70719, batch size: 4, num classes: 28\n",
      "\n",
      "Found 7395 images belonging to 28 classes.\n",
      "Val data loaded: total: 7395, batch size: 4, num classes: 28\n",
      "\n",
      "Epoch 1/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 1.2009 - accuracy: 0.6239\n",
      "Epoch 1: val_accuracy improved from -inf to 0.81669, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_80\\esophagus_28_EfficientNet-B4_20220620_01-0.817.hdf5\n",
      "17679/17679 [==============================] - 3321s 187ms/step - loss: 1.2009 - accuracy: 0.6239 - val_loss: 0.5472 - val_accuracy: 0.8167 - lr: 1.0000e-05\n",
      "Epoch 2/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.5972 - accuracy: 0.7987\n",
      "Epoch 2: val_accuracy improved from 0.81669 to 0.85119, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_80\\esophagus_28_EfficientNet-B4_20220620_02-0.851.hdf5\n",
      "17679/17679 [==============================] - 3311s 187ms/step - loss: 0.5972 - accuracy: 0.7987 - val_loss: 0.4408 - val_accuracy: 0.8512 - lr: 1.0000e-05\n",
      "Epoch 3/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.4783 - accuracy: 0.8360\n",
      "Epoch 3: val_accuracy improved from 0.85119 to 0.87378, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_80\\esophagus_28_EfficientNet-B4_20220620_03-0.874.hdf5\n",
      "17679/17679 [==============================] - 3328s 188ms/step - loss: 0.4783 - accuracy: 0.8360 - val_loss: 0.3619 - val_accuracy: 0.8738 - lr: 1.0000e-05\n",
      "Epoch 4/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.4094 - accuracy: 0.8576\n",
      "Epoch 4: val_accuracy did not improve from 0.87378\n",
      "17679/17679 [==============================] - 3320s 188ms/step - loss: 0.4094 - accuracy: 0.8576 - val_loss: 0.3646 - val_accuracy: 0.8732 - lr: 9.5028e-06\n",
      "Epoch 5/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.3591 - accuracy: 0.8742\n",
      "Epoch 5: val_accuracy improved from 0.87378 to 0.88312, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_80\\esophagus_28_EfficientNet-B4_20220620_05-0.883.hdf5\n",
      "17679/17679 [==============================] - 3320s 188ms/step - loss: 0.3591 - accuracy: 0.8742 - val_loss: 0.3424 - val_accuracy: 0.8831 - lr: 9.0303e-06\n",
      "Epoch 6/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.3155 - accuracy: 0.8895\n",
      "Epoch 6: val_accuracy improved from 0.88312 to 0.88528, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_80\\esophagus_28_EfficientNet-B4_20220620_06-0.885.hdf5\n",
      "17679/17679 [==============================] - 3322s 188ms/step - loss: 0.3155 - accuracy: 0.8895 - val_loss: 0.3570 - val_accuracy: 0.8853 - lr: 8.5813e-06\n",
      "Epoch 7/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.8994\n",
      "Epoch 7: val_accuracy improved from 0.88528 to 0.88677, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_80\\esophagus_28_EfficientNet-B4_20220620_07-0.887.hdf5\n",
      "17679/17679 [==============================] - 3313s 187ms/step - loss: 0.2851 - accuracy: 0.8994 - val_loss: 0.3356 - val_accuracy: 0.8868 - lr: 8.1546e-06\n",
      "Epoch 8/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.9097\n",
      "Epoch 8: val_accuracy did not improve from 0.88677\n",
      "17679/17679 [==============================] - 3289s 186ms/step - loss: 0.2517 - accuracy: 0.9097 - val_loss: 0.3806 - val_accuracy: 0.8833 - lr: 7.7492e-06\n",
      "Epoch 9/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 0.9212\n",
      "Epoch 9: val_accuracy improved from 0.88677 to 0.89245, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_80\\esophagus_28_EfficientNet-B4_20220620_09-0.892.hdf5\n",
      "17679/17679 [==============================] - 3284s 186ms/step - loss: 0.2215 - accuracy: 0.9212 - val_loss: 0.3716 - val_accuracy: 0.8925 - lr: 7.3639e-06\n",
      "Epoch 10/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.1957 - accuracy: 0.9298\n",
      "Epoch 10: val_accuracy improved from 0.89245 to 0.89286, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_80\\esophagus_28_EfficientNet-B4_20220620_10-0.893.hdf5\n",
      "17679/17679 [==============================] - 3286s 186ms/step - loss: 0.1957 - accuracy: 0.9298 - val_loss: 0.3616 - val_accuracy: 0.8929 - lr: 6.9977e-06\n",
      "Epoch 11/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.1728 - accuracy: 0.9360\n",
      "Epoch 11: val_accuracy did not improve from 0.89286\n",
      "17679/17679 [==============================] - 3287s 186ms/step - loss: 0.1728 - accuracy: 0.9360 - val_loss: 0.3638 - val_accuracy: 0.8914 - lr: 6.6498e-06\n",
      "Epoch 12/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.1502 - accuracy: 0.9453\n",
      "Epoch 12: val_accuracy did not improve from 0.89286\n",
      "17679/17679 [==============================] - 3288s 186ms/step - loss: 0.1502 - accuracy: 0.9453 - val_loss: 0.4187 - val_accuracy: 0.8873 - lr: 6.3192e-06\n",
      "Epoch 13/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.9524\n",
      "Epoch 13: val_accuracy did not improve from 0.89286\n",
      "17679/17679 [==============================] - 3293s 186ms/step - loss: 0.1309 - accuracy: 0.9524 - val_loss: 0.4343 - val_accuracy: 0.8900 - lr: 6.0050e-06\n",
      "Best ckpt Selected: D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_80\\esophagus_28_EfficientNet-B4_20220620_10-0.893.hdf5\n",
      "475\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 380, 380, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, 12, 12, 1792)     17673823  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1792)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                50204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,724,027\n",
      "Trainable params: 17,414,732\n",
      "Non-trainable params: 309,295\n",
      "_________________________________________________________________\n",
      "Found 70719 images belonging to 28 classes.\n",
      "Train data loaded: total: 70719, batch size: 4, num classes: 28\n",
      "\n",
      "Found 7395 images belonging to 28 classes.\n",
      "Val data loaded: total: 7395, batch size: 4, num classes: 28\n",
      "\n",
      "Epoch 1/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.9490\n",
      "Epoch 1: val_accuracy improved from -inf to 0.89353, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_80\\esophagus_28_EfficientNet-B4_20220621_01-0.894.hdf5\n",
      "17679/17679 [==============================] - 3305s 186ms/step - loss: 0.1400 - accuracy: 0.9490 - val_loss: 0.3994 - val_accuracy: 0.8935 - lr: 1.0000e-06\n",
      "Epoch 2/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9533\n",
      "Epoch 2: val_accuracy improved from 0.89353 to 0.89421, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_80\\esophagus_28_EfficientNet-B4_20220621_02-0.894.hdf5\n",
      "17679/17679 [==============================] - 3296s 186ms/step - loss: 0.1288 - accuracy: 0.9533 - val_loss: 0.3901 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 3/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9579\n",
      "Epoch 3: val_accuracy did not improve from 0.89421\n",
      "17679/17679 [==============================] - 3295s 186ms/step - loss: 0.1190 - accuracy: 0.9579 - val_loss: 0.4159 - val_accuracy: 0.8938 - lr: 1.0000e-06\n",
      "Epoch 4/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9589\n",
      "Epoch 4: val_accuracy did not improve from 0.89421\n",
      "17679/17679 [==============================] - 3296s 186ms/step - loss: 0.1148 - accuracy: 0.9589 - val_loss: 0.4201 - val_accuracy: 0.8929 - lr: 9.5028e-07\n",
      "Epoch 5/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.1135 - accuracy: 0.9589\n",
      "Epoch 5: val_accuracy did not improve from 0.89421\n",
      "17679/17679 [==============================] - 3332s 188ms/step - loss: 0.1135 - accuracy: 0.9589 - val_loss: 0.4154 - val_accuracy: 0.8933 - lr: 9.0303e-07\n",
      "esophagus_28_EfficientNet-B4_20220617_TransferBase-0.241.hdf5\n",
      "Best ckpt Selected: D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_20220617_TransferBase-0.241.hdf5\n",
      "475\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 380, 380, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, 12, 12, 1792)     17673823  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1792)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                50204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,724,027\n",
      "Trainable params: 17,181,380\n",
      "Non-trainable params: 542,647\n",
      "_________________________________________________________________\n",
      "Found 70719 images belonging to 28 classes.\n",
      "Train data loaded: total: 70719, batch size: 4, num classes: 28\n",
      "\n",
      "Found 7395 images belonging to 28 classes.\n",
      "Val data loaded: total: 7395, batch size: 4, num classes: 28\n",
      "\n",
      "Epoch 1/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 1.4460 - accuracy: 0.5529\n",
      "Epoch 1: val_accuracy improved from -inf to 0.78477, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_160\\esophagus_28_EfficientNet-B4_20220621_01-0.785.hdf5\n",
      "17679/17679 [==============================] - 2628s 148ms/step - loss: 1.4460 - accuracy: 0.5529 - val_loss: 0.6544 - val_accuracy: 0.7848 - lr: 1.0000e-05\n",
      "Epoch 2/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.7198 - accuracy: 0.7597\n",
      "Epoch 2: val_accuracy improved from 0.78477 to 0.83185, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_160\\esophagus_28_EfficientNet-B4_20220621_02-0.832.hdf5\n",
      "17679/17679 [==============================] - 2569s 145ms/step - loss: 0.7198 - accuracy: 0.7597 - val_loss: 0.4993 - val_accuracy: 0.8318 - lr: 1.0000e-05\n",
      "Epoch 3/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.5655 - accuracy: 0.8080\n",
      "Epoch 3: val_accuracy improved from 0.83185 to 0.84848, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_160\\esophagus_28_EfficientNet-B4_20220621_03-0.848.hdf5\n",
      "17679/17679 [==============================] - 2583s 146ms/step - loss: 0.5655 - accuracy: 0.8080 - val_loss: 0.4527 - val_accuracy: 0.8485 - lr: 1.0000e-05\n",
      "Epoch 4/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.8321\n",
      "Epoch 4: val_accuracy improved from 0.84848 to 0.86310, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_160\\esophagus_28_EfficientNet-B4_20220621_04-0.863.hdf5\n",
      "17679/17679 [==============================] - 2565s 145ms/step - loss: 0.4846 - accuracy: 0.8321 - val_loss: 0.4083 - val_accuracy: 0.8631 - lr: 9.5028e-06\n",
      "Epoch 5/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.8523\n",
      "Epoch 5: val_accuracy improved from 0.86310 to 0.86567, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_160\\esophagus_28_EfficientNet-B4_20220621_05-0.866.hdf5\n",
      "17679/17679 [==============================] - 2569s 145ms/step - loss: 0.4278 - accuracy: 0.8523 - val_loss: 0.3915 - val_accuracy: 0.8657 - lr: 9.0303e-06\n",
      "Epoch 6/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8646\n",
      "Epoch 6: val_accuracy did not improve from 0.86567\n",
      "17679/17679 [==============================] - 2573s 146ms/step - loss: 0.3858 - accuracy: 0.8646 - val_loss: 0.4415 - val_accuracy: 0.8613 - lr: 8.5813e-06\n",
      "Epoch 7/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.8778\n",
      "Epoch 7: val_accuracy improved from 0.86567 to 0.87852, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_160\\esophagus_28_EfficientNet-B4_20220621_07-0.879.hdf5\n",
      "17679/17679 [==============================] - 2572s 145ms/step - loss: 0.3489 - accuracy: 0.8778 - val_loss: 0.3682 - val_accuracy: 0.8785 - lr: 8.1546e-06\n",
      "Epoch 8/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.8877\n",
      "Epoch 8: val_accuracy did not improve from 0.87852\n",
      "17679/17679 [==============================] - 2586s 146ms/step - loss: 0.3186 - accuracy: 0.8877 - val_loss: 0.3806 - val_accuracy: 0.8766 - lr: 7.7492e-06\n",
      "Epoch 9/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.8980\n",
      "Epoch 9: val_accuracy did not improve from 0.87852\n",
      "17679/17679 [==============================] - 2560s 145ms/step - loss: 0.2847 - accuracy: 0.8980 - val_loss: 0.3876 - val_accuracy: 0.8777 - lr: 7.3639e-06\n",
      "Epoch 10/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2630 - accuracy: 0.9063\n",
      "Epoch 10: val_accuracy did not improve from 0.87852\n",
      "17679/17679 [==============================] - 2579s 146ms/step - loss: 0.2630 - accuracy: 0.9063 - val_loss: 0.3974 - val_accuracy: 0.8768 - lr: 6.9977e-06\n",
      "Best ckpt Selected: D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_160\\esophagus_28_EfficientNet-B4_20220621_07-0.879.hdf5\n",
      "475\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 380, 380, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, 12, 12, 1792)     17673823  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1792)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                50204     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,724,027\n",
      "Trainable params: 17,181,380\n",
      "Non-trainable params: 542,647\n",
      "_________________________________________________________________\n",
      "Found 70719 images belonging to 28 classes.\n",
      "Train data loaded: total: 70719, batch size: 4, num classes: 28\n",
      "\n",
      "Found 7395 images belonging to 28 classes.\n",
      "Val data loaded: total: 7395, batch size: 4, num classes: 28\n",
      "\n",
      "Epoch 1/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2777 - accuracy: 0.9006\n",
      "Epoch 1: val_accuracy improved from -inf to 0.88420, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_160\\esophagus_28_EfficientNet-B4_20220621_01-0.884.hdf5\n",
      "17679/17679 [==============================] - 2602s 147ms/step - loss: 0.2777 - accuracy: 0.9006 - val_loss: 0.3673 - val_accuracy: 0.8842 - lr: 1.0000e-06\n",
      "Epoch 2/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2645 - accuracy: 0.9066\n",
      "Epoch 2: val_accuracy improved from 0.88420 to 0.88555, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_160\\esophagus_28_EfficientNet-B4_20220621_02-0.886.hdf5\n",
      "17679/17679 [==============================] - 2585s 146ms/step - loss: 0.2645 - accuracy: 0.9066 - val_loss: 0.3677 - val_accuracy: 0.8856 - lr: 1.0000e-06\n",
      "Epoch 3/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.9085\n",
      "Epoch 3: val_accuracy improved from 0.88555 to 0.88636, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_160\\esophagus_28_EfficientNet-B4_20220621_03-0.886.hdf5\n",
      "17679/17679 [==============================] - 2565s 145ms/step - loss: 0.2573 - accuracy: 0.9085 - val_loss: 0.3693 - val_accuracy: 0.8864 - lr: 1.0000e-06\n",
      "Epoch 4/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2519 - accuracy: 0.9095\n",
      "Epoch 4: val_accuracy did not improve from 0.88636\n",
      "17679/17679 [==============================] - 2539s 144ms/step - loss: 0.2519 - accuracy: 0.9095 - val_loss: 0.3726 - val_accuracy: 0.8864 - lr: 9.5028e-07\n",
      "Epoch 5/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.9137\n",
      "Epoch 5: val_accuracy did not improve from 0.88636\n",
      "17679/17679 [==============================] - 2536s 143ms/step - loss: 0.2443 - accuracy: 0.9137 - val_loss: 0.3722 - val_accuracy: 0.8845 - lr: 9.0303e-07\n",
      "Epoch 6/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9153\n",
      "Epoch 6: val_accuracy improved from 0.88636 to 0.88745, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_160\\esophagus_28_EfficientNet-B4_20220621_06-0.887.hdf5\n",
      "17679/17679 [==============================] - 2540s 144ms/step - loss: 0.2363 - accuracy: 0.9153 - val_loss: 0.3778 - val_accuracy: 0.8874 - lr: 8.5813e-07\n",
      "Epoch 7/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.9172\n",
      "Epoch 7: val_accuracy did not improve from 0.88745\n",
      "17679/17679 [==============================] - 2541s 144ms/step - loss: 0.2317 - accuracy: 0.9172 - val_loss: 0.3808 - val_accuracy: 0.8862 - lr: 8.1546e-07\n",
      "Epoch 8/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2310 - accuracy: 0.9172\n",
      "Epoch 8: val_accuracy did not improve from 0.88745\n",
      "17679/17679 [==============================] - 2538s 144ms/step - loss: 0.2310 - accuracy: 0.9172 - val_loss: 0.3940 - val_accuracy: 0.8828 - lr: 7.7492e-07\n",
      "Epoch 9/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.9200\n",
      "Epoch 9: val_accuracy did not improve from 0.88745\n",
      "17679/17679 [==============================] - 2541s 144ms/step - loss: 0.2244 - accuracy: 0.9200 - val_loss: 0.3878 - val_accuracy: 0.8846 - lr: 7.3639e-07\n"
     ]
    }
   ],
   "source": [
    "mdl_idx, data_idx = 2, 0\n",
    "for uf_layer in [80, 160]:\n",
    "    finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx, uf_layer), 1e-5, uf_layer, 30, 4)\n",
    "    finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx, uf_layer), 1e-6, uf_layer, 30, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c74561d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esophagus_28_EfficientNet-B4_20220617_TransferBase-0.241.hdf5\n",
      "Best ckpt Selected: D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_20220617_TransferBase-0.241.hdf5\n",
      "475\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 380, 380, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, 12, 12, 1792)     17673823  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1792)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                50204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,724,027\n",
      "Trainable params: 17,473,620\n",
      "Non-trainable params: 250,407\n",
      "_________________________________________________________________\n",
      "Found 70719 images belonging to 28 classes.\n",
      "Train data loaded: total: 70719, batch size: 4, num classes: 28\n",
      "\n",
      "Found 7395 images belonging to 28 classes.\n",
      "Val data loaded: total: 7395, batch size: 4, num classes: 28\n",
      "\n",
      "Epoch 1/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 1.1400 - accuracy: 0.6393\n",
      "Epoch 1: val_accuracy improved from -inf to 0.82968, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_0\\esophagus_28_EfficientNet-B4_20220621_01-0.830.hdf5\n",
      "17679/17679 [==============================] - 5309s 300ms/step - loss: 1.1400 - accuracy: 0.6393 - val_loss: 0.5086 - val_accuracy: 0.8297 - lr: 1.0000e-05\n",
      "Epoch 2/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.8082\n",
      "Epoch 2: val_accuracy improved from 0.82968 to 0.86688, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_0\\esophagus_28_EfficientNet-B4_20220621_02-0.867.hdf5\n",
      "17679/17679 [==============================] - 5301s 300ms/step - loss: 0.5645 - accuracy: 0.8082 - val_loss: 0.3914 - val_accuracy: 0.8669 - lr: 1.0000e-05\n",
      "Epoch 3/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.8435\n",
      "Epoch 3: val_accuracy improved from 0.86688 to 0.87189, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_0\\esophagus_28_EfficientNet-B4_20220621_03-0.872.hdf5\n",
      "17679/17679 [==============================] - 5307s 300ms/step - loss: 0.4528 - accuracy: 0.8435 - val_loss: 0.3627 - val_accuracy: 0.8719 - lr: 1.0000e-05\n",
      "Epoch 4/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8647\n",
      "Epoch 4: val_accuracy improved from 0.87189 to 0.87946, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_0\\esophagus_28_EfficientNet-B4_20220621_04-0.879.hdf5\n",
      "17679/17679 [==============================] - 5290s 299ms/step - loss: 0.3883 - accuracy: 0.8647 - val_loss: 0.3410 - val_accuracy: 0.8795 - lr: 9.5028e-06\n",
      "Epoch 5/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.8813\n",
      "Epoch 5: val_accuracy improved from 0.87946 to 0.89150, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_0\\esophagus_28_EfficientNet-B4_20220621_05-0.892.hdf5\n",
      "17679/17679 [==============================] - 5290s 299ms/step - loss: 0.3372 - accuracy: 0.8813 - val_loss: 0.3167 - val_accuracy: 0.8915 - lr: 9.0303e-06\n",
      "Epoch 6/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2981 - accuracy: 0.8942\n",
      "Epoch 6: val_accuracy did not improve from 0.89150\n",
      "17679/17679 [==============================] - 5302s 300ms/step - loss: 0.2981 - accuracy: 0.8942 - val_loss: 0.3359 - val_accuracy: 0.8869 - lr: 8.5813e-06\n",
      "Epoch 7/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2625 - accuracy: 0.9059\n",
      "Epoch 7: val_accuracy did not improve from 0.89150\n",
      "17679/17679 [==============================] - 5305s 300ms/step - loss: 0.2625 - accuracy: 0.9059 - val_loss: 0.3259 - val_accuracy: 0.8903 - lr: 8.1546e-06\n",
      "Epoch 8/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2358 - accuracy: 0.9147\n",
      "Epoch 8: val_accuracy did not improve from 0.89150\n",
      "17679/17679 [==============================] - 5336s 302ms/step - loss: 0.2358 - accuracy: 0.9147 - val_loss: 0.3539 - val_accuracy: 0.8915 - lr: 7.7492e-06\n",
      "Best ckpt Selected: D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_0\\esophagus_28_EfficientNet-B4_20220621_05-0.892.hdf5\n",
      "475\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 380, 380, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, 12, 12, 1792)     17673823  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1792)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                50204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,724,027\n",
      "Trainable params: 17,473,620\n",
      "Non-trainable params: 250,407\n",
      "_________________________________________________________________\n",
      "Found 70719 images belonging to 28 classes.\n",
      "Train data loaded: total: 70719, batch size: 4, num classes: 28\n",
      "\n",
      "Found 7395 images belonging to 28 classes.\n",
      "Val data loaded: total: 7395, batch size: 4, num classes: 28\n",
      "\n",
      "Epoch 1/30\n",
      " 3890/17679 [=====>........................] - ETA: 1:08:32 - loss: 0.2699 - accuracy: 0.9062"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  OSError: [Errno 22] Invalid argument: '\\\\\\\\192.168.0.154\\\\数据\\\\口咽部\\\\大部位27分类\\\\res_train_2\\\\15\\\\15-010001_0_001_2018_11_08_11_30_261_0_c81.jpg'\nTraceback (most recent call last):\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1030, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 831, in wrapped_generator\n    for data in generator_fn():\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 957, in generator_fn\n    yield x[i]\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 110, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 337, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 393, in load_img\n    with open(path, 'rb') as f:\n\nOSError: [Errno 22] Invalid argument: '\\\\\\\\192.168.0.154\\\\数据\\\\口咽部\\\\大部位27分类\\\\res_train_2\\\\15\\\\15-010001_0_001_2018_11_08_11_30_261_0_c81.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  OSError: [Errno 22] Invalid argument: '\\\\\\\\192.168.0.154\\\\数据\\\\口咽部\\\\大部位27分类\\\\res_train_2\\\\15\\\\15-010001_0_001_2018_11_08_11_30_261_0_c81.jpg'\nTraceback (most recent call last):\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1030, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 831, in wrapped_generator\n    for data in generator_fn():\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 957, in generator_fn\n    yield x[i]\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 110, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 337, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 393, in load_img\n    with open(path, 'rb') as f:\n\nOSError: [Errno 22] Invalid argument: '\\\\\\\\192.168.0.154\\\\数据\\\\口咽部\\\\大部位27分类\\\\res_train_2\\\\15\\\\15-010001_0_001_2018_11_08_11_30_261_0_c81.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_4918850]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m uf_layer \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m      3\u001b[0m     finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx, uf_layer), \u001b[38;5;241m1e-5\u001b[39m, uf_layer, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mfinetune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdl_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfind_best_chkpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdl_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muf_layer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muf_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mfinetune\u001b[1;34m(mdl_idx, data_idx, chpkt_path, init_lr, unfrozen_layers, epochs, batch_size)\u001b[0m\n\u001b[0;32m     24\u001b[0m train_gen, val_gen \u001b[38;5;241m=\u001b[39m load_data(data_type, img_shape, BATCH_SIZE)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 训练\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodl_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munfrozen_layers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  OSError: [Errno 22] Invalid argument: '\\\\\\\\192.168.0.154\\\\数据\\\\口咽部\\\\大部位27分类\\\\res_train_2\\\\15\\\\15-010001_0_001_2018_11_08_11_30_261_0_c81.jpg'\nTraceback (most recent call last):\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1030, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 831, in wrapped_generator\n    for data in generator_fn():\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 957, in generator_fn\n    yield x[i]\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 110, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 337, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 393, in load_img\n    with open(path, 'rb') as f:\n\nOSError: [Errno 22] Invalid argument: '\\\\\\\\192.168.0.154\\\\数据\\\\口咽部\\\\大部位27分类\\\\res_train_2\\\\15\\\\15-010001_0_001_2018_11_08_11_30_261_0_c81.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  OSError: [Errno 22] Invalid argument: '\\\\\\\\192.168.0.154\\\\数据\\\\口咽部\\\\大部位27分类\\\\res_train_2\\\\15\\\\15-010001_0_001_2018_11_08_11_30_261_0_c81.jpg'\nTraceback (most recent call last):\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1030, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 831, in wrapped_generator\n    for data in generator_fn():\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 957, in generator_fn\n    yield x[i]\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 110, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 337, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"D:\\Anaconda3\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 393, in load_img\n    with open(path, 'rb') as f:\n\nOSError: [Errno 22] Invalid argument: '\\\\\\\\192.168.0.154\\\\数据\\\\口咽部\\\\大部位27分类\\\\res_train_2\\\\15\\\\15-010001_0_001_2018_11_08_11_30_261_0_c81.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_4918850]"
     ]
    }
   ],
   "source": [
    "mdl_idx, data_idx = 2, 0\n",
    "for uf_layer in [0]:\n",
    "    finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx, uf_layer), 1e-5, uf_layer, 30, 4)\n",
    "    finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx, uf_layer), 1e-6, uf_layer, 30, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de4245e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ckpt Selected: D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_0\\esophagus_28_EfficientNet-B4_20220621_05-0.892.hdf5\n",
      "475\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 380, 380, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb4 (Functional)  (None, 12, 12, 1792)     17673823  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1792)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 28)                50204     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,724,027\n",
      "Trainable params: 17,473,620\n",
      "Non-trainable params: 250,407\n",
      "_________________________________________________________________\n",
      "Found 70719 images belonging to 28 classes.\n",
      "Train data loaded: total: 70719, batch size: 4, num classes: 28\n",
      "\n",
      "Found 7395 images belonging to 28 classes.\n",
      "Val data loaded: total: 7395, batch size: 4, num classes: 28\n",
      "\n",
      "Epoch 1/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.9067\n",
      "Epoch 1: val_accuracy improved from -inf to 0.89692, saving model to D:\\projects\\Vision\\ckpts\\esophagus_28_EfficientNet-B4_0\\esophagus_28_EfficientNet-B4_20220622_01-0.897.hdf5\n",
      "17679/17679 [==============================] - 5388s 304ms/step - loss: 0.2607 - accuracy: 0.9067 - val_loss: 0.3054 - val_accuracy: 0.8969 - lr: 1.0000e-06\n",
      "Epoch 2/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.9119\n",
      "Epoch 2: val_accuracy did not improve from 0.89692\n",
      "17679/17679 [==============================] - 5370s 304ms/step - loss: 0.2465 - accuracy: 0.9119 - val_loss: 0.3183 - val_accuracy: 0.8958 - lr: 1.0000e-06\n",
      "Epoch 3/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2376 - accuracy: 0.9142\n",
      "Epoch 3: val_accuracy did not improve from 0.89692\n",
      "17679/17679 [==============================] - 5358s 303ms/step - loss: 0.2376 - accuracy: 0.9142 - val_loss: 0.3155 - val_accuracy: 0.8954 - lr: 1.0000e-06\n",
      "Epoch 4/30\n",
      "17679/17679 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9192\n",
      "Epoch 4: val_accuracy did not improve from 0.89692\n",
      "17679/17679 [==============================] - 5390s 305ms/step - loss: 0.2279 - accuracy: 0.9192 - val_loss: 0.3239 - val_accuracy: 0.8949 - lr: 9.5028e-07\n"
     ]
    }
   ],
   "source": [
    "mdl_idx, data_idx = 2, 0\n",
    "for uf_layer in [0]:\n",
    "    finetune(mdl_idx, data_idx, find_best_chkpt(mdl_idx, data_idx, uf_layer), 1e-6, uf_layer, 30, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b934b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

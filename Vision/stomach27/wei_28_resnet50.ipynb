{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 体内外数据训练\n",
    "## 导入相应的包\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T10:17:37.973172Z",
     "start_time": "2022-05-30T10:17:34.971680Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.keras.preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_19540/3941584761.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.keras.preprocessing'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.python.keras.applications import MobileNetV2, ResNet50\n",
    "from tensorflow.python.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.python.keras.models import Model, model_from_json\n",
    "# 添加路径，以能正常导入mbsh、trainer\n",
    "sys.path.insert(0, r\"E:\\projects\\znyx-trainer\\trainer\")\n",
    "\n",
    "\n",
    "\n",
    "from mbsh import create_app\n",
    "from mbsh.core.models import SmallModel\n",
    "from mbsh.core.images import read_to_pd,TrainArgs\n",
    "from mbsh.core.plot import Plot\n",
    "\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T10:17:38.817064Z",
     "start_time": "2022-05-30T10:17:37.974169Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_id = 100 ResNet 模型 loss: 0.2732 - acc: 0.9096 - val_loss: 0.4109 - val_acc: 0.8740\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7  # 程序最多只能占用指定gpu70%的显存\n",
    "config.gpu_options.allow_growth = True      #程序按需申请内存\n",
    "sess = tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  路径常量设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T10:17:41.225956Z",
     "start_time": "2022-05-30T10:17:41.218947Z"
    }
   },
   "outputs": [],
   "source": [
    "# 样本数据根目录\n",
    "# 根目录下res中按分类标签存放各类型图像\n",
    "# cache目录存放训练的结果模型\n",
    "# \n",
    "root_path = r\"\\\\192.168.0.154\\数据\\口咽部\\大部位27分类\"\n",
    "\n",
    "# 是否使用平衡数据做训练\n",
    "use_increase = False\n",
    "\n",
    "# 训练采用的模型名称\n",
    "model_name = 'resnet'\n",
    "\n",
    "# 模型保存id\n",
    "model_id = 28011\n",
    "\n",
    "\n",
    "IMG_SIZE = 224\n",
    "img_size = (IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "# img_size = (360,360)\n",
    "# 训练迭代次数\n",
    "epochs = 3\n",
    "\n",
    "\n",
    "# 训练每批次样本数\n",
    "batch_size = 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T10:17:42.033766Z",
     "start_time": "2022-05-30T10:17:42.019808Z"
    }
   },
   "outputs": [],
   "source": [
    "# app创建\n",
    "app = create_app(os.getenv('FLASK_CONFIG') or 'default')\n",
    "app.app_context().push()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T10:17:42.623759Z",
     "start_time": "2022-05-30T10:17:42.602779Z"
    }
   },
   "outputs": [],
   "source": [
    "cache_path = root_path + '/cache'\n",
    "res_path = root_path + '/res'\n",
    "\n",
    "# res数据分割后的训练和验证集目录\n",
    "res_train_path = root_path + '/res_train'\n",
    "res_test_path = root_path + '/res_val'\n",
    "\n",
    "# 数据平衡后的训练和验证集目录\n",
    "train_path = root_path + '/train'\n",
    "test_path = root_path + '/val'\n",
    "\n",
    "# 图片预测错误存放目录\n",
    "pred_err_path = root_path + '/pred_err'\n",
    "\n",
    "\n",
    "# trainer创建\n",
    "\n",
    "# 从数据库获取model信息，如果数据库还未建立相应的记录可查询一个已存在的，再自行修改sm的desc_list\n",
    "# sm = SmallModel.query.get(sm_name)\n",
    "\n",
    "# 生成 trainer\n",
    "sm_name = '胃27模型'\n",
    "sm_desc_list =  ['无法判断', '食管', '贲门', '胃窦#大弯', '胃窦#后壁', '胃窦#前壁', '胃窦#小弯', '十二指肠球部', \n",
    "                 '十二指肠降部', '正镜胃体下部#大弯', '正镜胃体下部#后壁', '正镜胃体下部#前壁', '正镜胃体下部#小弯',\n",
    "                 '正镜胃体中上部#大弯', '正镜胃体中上部#后壁', '正镜胃体中上部#前壁', '正镜胃体中上部#小弯','倒镜胃底#大弯', \n",
    "                 '倒镜胃底#后壁', '倒镜胃底#前壁', '倒镜胃底#小弯','倒镜胃体中上部#后壁', '倒镜胃体中上部#前壁', \n",
    "                 '倒镜胃体中上部#小弯','倒镜胃角#后壁', '倒镜胃角#前壁', '倒镜胃角#小弯', '胃#咽部']\n",
    "sm = SmallModel(sm_name)\n",
    "\n",
    "\n",
    "sm.desc_list = sm_desc_list\n",
    "trainer = Trainer(sm)\n",
    "trainer.img_size = img_size\n",
    "trainer.target_fold = root_path\n",
    "\n",
    "# 类型个数\n",
    "types_num = len(trainer.desc_list)\n",
    "\n",
    "desc_list = [str(x) + '-' + trainer.desc_list[x] for x in range(0,types_num)]\n",
    "print(desc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练\n",
    "### 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T10:17:48.167129Z",
     "start_time": "2022-05-30T10:17:44.098930Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_19540/2379928833.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 图片生成器\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# https://keras-cn.readthedocs.io/en/latest/preprocessing/image/#imagedatagenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m train_datagen =  ImageDataGenerator(       \n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mwidth_shift_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mheight_shift_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "def img_rgb2_bgr(img):\n",
    "    return img[: , : , : : -1]\n",
    "\n",
    "# 图片生成器\n",
    "# https://keras-cn.readthedocs.io/en/latest/preprocessing/image/#imagedatagenerator\n",
    "train_datagen =  ImageDataGenerator(       \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        rotation_range=10,\n",
    "        zoom_range=0.1,\n",
    "        fill_mode='constant',\n",
    "#         vertical_flip=True,\n",
    "#         horizontal_flip=True,\n",
    "        preprocessing_function = img_rgb2_bgr,\n",
    "    )\n",
    "\n",
    "test_datagen =  ImageDataGenerator(\n",
    "        fill_mode='constant',\n",
    "        preprocessing_function = img_rgb2_bgr,\n",
    "    )\n",
    "\n",
    "# 训练数据与测试数据\n",
    "cls_mode = 'binary' if types_num == 2 else 'categorical'\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        res_train_path,\n",
    "        target_size = img_size,\n",
    "        batch_size = batch_size,\n",
    "        class_mode = cls_mode)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        res_test_path,\n",
    "        target_size = img_size,\n",
    "        batch_size = batch_size,\n",
    "        class_mode = cls_mode)\n",
    "\n",
    "train_samples = train_generator.samples\n",
    "valid_samples = test_generator.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "#### 先全部冻结训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T10:17:54.038112Z",
     "start_time": "2022-05-30T10:17:49.378580Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "# Create the base model Resnet50\n",
    "base_model = ResNet50(input_shape=IMG_SHAPE,include_top=False, weights='imagenet')\n",
    "# base_model = MobileNetV2(input_shape=IMG_SHAPE,include_top=False, weights='imagenet')\n",
    "# 冻结所有层\n",
    "base_model.trainable = False\n",
    "# base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T10:17:54.162511Z",
     "start_time": "2022-05-30T10:17:54.039049Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.optimizers import SGD\n",
    "setting = (1, 'sigmoid', 'binary_crossentropy') if types_num == 2 else (types_num, 'softmax', 'categorical_crossentropy')\n",
    "# Add a classification head\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "prediction = Dense(setting[0], activation=setting[1], name='dense')(x)\n",
    "\n",
    "model = Model(base_model.input, prediction)\n",
    "\n",
    "    \n",
    "base_learning_rate = 0.0001\n",
    "sgd = SGD(lr=base_learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss=setting[2], metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T10:17:54.177475Z",
     "start_time": "2022-05-30T10:17:54.163510Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_gen(model, model_id, epochs=5):\n",
    "    class_mode = 'binary' if types_num == 2 else 'categorical'\n",
    "    print(\"train from imgs model_id=%s ,class_mode=%s\" % (model_id, class_mode))\n",
    "                \n",
    "    # 创建cache目录\n",
    "    if not os.path.exists(cache_path):\n",
    "        os.mkdir(cache_path)\n",
    "    \n",
    "    weight_path = cache_path + '/weights' + str(model_id) + '.hdf5'\n",
    "    \n",
    "    # EarlyStoppingy原型：\n",
    "    # EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "    # ModelCheckpoint原型：\n",
    "    # ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "    check_point = ModelCheckpoint(weight_path, monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "    \n",
    "    # callbacks设置\n",
    "    callbacks = [early_stop, check_point]\n",
    "    \n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs = epochs,\n",
    "        steps_per_epoch = train_samples // batch_size,\n",
    "        validation_data = test_generator,\n",
    "        validation_steps = valid_samples // batch_size,\n",
    "        callbacks = callbacks)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T13:56:55.965939Z",
     "start_time": "2022-05-30T10:17:54.178469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train from imgs model_id=28011 ,class_mode=categorical\n",
      "Epoch 1/20\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 1.3055 - acc: 0.6039WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 18:33:26,535 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 930s 211ms/step - loss: 1.3053 - acc: 0.6039 - val_loss: 0.4890 - val_acc: 0.8348\n",
      "Epoch 2/20\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 0.6346 - acc: 0.7880WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 18:46:09,907 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 762s 173ms/step - loss: 0.6347 - acc: 0.7879 - val_loss: 0.4057 - val_acc: 0.8575\n",
      "Epoch 3/20\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 0.5246 - acc: 0.8238WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 18:59:08,254 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 778s 177ms/step - loss: 0.5247 - acc: 0.8238 - val_loss: 0.4009 - val_acc: 0.8615\n",
      "Epoch 4/20\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 0.4687 - acc: 0.8413WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 19:12:02,127 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 774s 176ms/step - loss: 0.4687 - acc: 0.8413 - val_loss: 0.3555 - val_acc: 0.8726\n",
      "Epoch 5/20\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 0.4249 - acc: 0.8548WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 19:24:40,750 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 759s 172ms/step - loss: 0.4250 - acc: 0.8547 - val_loss: 0.3481 - val_acc: 0.8776\n",
      "Epoch 6/20\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 0.3933 - acc: 0.8646WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 19:37:14,735 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 754s 171ms/step - loss: 0.3933 - acc: 0.8646 - val_loss: 0.3316 - val_acc: 0.8851\n",
      "Epoch 7/20\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 0.3656 - acc: 0.8747WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 19:49:45,346 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217C61B1748>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 750s 170ms/step - loss: 0.3656 - acc: 0.8747 - val_loss: 0.3168 - val_acc: 0.8868\n",
      "Epoch 8/20\n",
      "4409/4409 [==============================] - 778s 176ms/step - loss: 0.3404 - acc: 0.8824 - val_loss: 0.3170 - val_acc: 0.8885\n",
      "Epoch 9/20\n",
      "4409/4409 [==============================] - 821s 186ms/step - loss: 0.3209 - acc: 0.8885 - val_loss: 0.3215 - val_acc: 0.8914\n",
      "Epoch 10/20\n",
      "4409/4409 [==============================] - 772s 175ms/step - loss: 0.3008 - acc: 0.8954 - val_loss: 0.3437 - val_acc: 0.8835\n",
      "Epoch 11/20\n",
      "4409/4409 [==============================] - 775s 176ms/step - loss: 0.2832 - acc: 0.9025 - val_loss: 0.3405 - val_acc: 0.8857\n",
      "Epoch 12/20\n",
      "4409/4409 [==============================] - 760s 172ms/step - loss: 0.2684 - acc: 0.9058 - val_loss: 0.3180 - val_acc: 0.8919\n",
      "Epoch 13/20\n",
      "4409/4409 [==============================] - 753s 171ms/step - loss: 0.2518 - acc: 0.9120 - val_loss: 0.3572 - val_acc: 0.8842\n",
      "Epoch 14/20\n",
      "4409/4409 [==============================] - 735s 167ms/step - loss: 0.2376 - acc: 0.9173 - val_loss: 0.3310 - val_acc: 0.8906\n",
      "Epoch 15/20\n",
      "4409/4409 [==============================] - 738s 167ms/step - loss: 0.2251 - acc: 0.9209 - val_loss: 0.3283 - val_acc: 0.8925\n",
      "Epoch 16/20\n",
      "4409/4409 [==============================] - 723s 164ms/step - loss: 0.2091 - acc: 0.9258 - val_loss: 0.3540 - val_acc: 0.8885\n",
      "Epoch 17/20\n",
      "4409/4409 [==============================] - 774s 176ms/step - loss: 0.2006 - acc: 0.9295 - val_loss: 0.3556 - val_acc: 0.8860\n"
     ]
    }
   ],
   "source": [
    "history = fit_gen(model, model_id, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T13:56:56.189369Z",
     "start_time": "2022-05-30T13:56:55.966937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  175\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "# 在 fine_tune_at 之后放开训练,根据情况修改 \n",
    "fine_tune_at = 120\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False\n",
    "    \n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "prediction = Dense(setting[0], activation=setting[1], name='dense')(x)\n",
    "\n",
    "model = Model(base_model.input, prediction)\n",
    "\n",
    "    \n",
    "# base_learning_rate = 0.0001\n",
    "sgd = SGD(lr=base_learning_rate/10, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss=setting[2], metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T17:34:15.410477Z",
     "start_time": "2022-05-30T13:56:56.190371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train from imgs model_id=28011 ,class_mode=categorical\n",
      "Epoch 1/100\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 1.6631 - acc: 0.5736WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:09:54,190 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 778s 176ms/step - loss: 1.6629 - acc: 0.5737 - val_loss: 0.5163 - val_acc: 0.8649\n",
      "Epoch 2/100\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 0.5764 - acc: 0.8469WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:22:46,156 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 771s 175ms/step - loss: 0.5764 - acc: 0.8468 - val_loss: 0.3885 - val_acc: 0.8778\n",
      "Epoch 3/100\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 0.4337 - acc: 0.8722WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:35:08,513 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 742s 168ms/step - loss: 0.4337 - acc: 0.8721 - val_loss: 0.3632 - val_acc: 0.8826\n",
      "Epoch 4/100\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 0.3833 - acc: 0.8829WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:47:25,063 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 737s 167ms/step - loss: 0.3832 - acc: 0.8829 - val_loss: 0.3561 - val_acc: 0.8868\n",
      "Epoch 5/100\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 0.3465 - acc: 0.8919WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 22:59:17,410 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 713s 162ms/step - loss: 0.3465 - acc: 0.8919 - val_loss: 0.3535 - val_acc: 0.8857\n",
      "Epoch 6/100\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 0.3258 - acc: 0.8964WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 23:11:05,171 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 707s 160ms/step - loss: 0.3257 - acc: 0.8965 - val_loss: 0.3523 - val_acc: 0.8880\n",
      "Epoch 7/100\n",
      "4409/4409 [==============================] - 699s 158ms/step - loss: 0.3060 - acc: 0.9018 - val_loss: 0.3528 - val_acc: 0.8887\n",
      "Epoch 8/100\n",
      "4408/4409 [============================>.] - ETA: 0s - loss: 0.2936 - acc: 0.9051WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 23:34:19,880 - WARNING - tf_logging.py - warning - 125 - This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.SGD object at 0x00000217D11E0940>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409/4409 [==============================] - 696s 158ms/step - loss: 0.2935 - acc: 0.9051 - val_loss: 0.3511 - val_acc: 0.8881\n",
      "Epoch 9/100\n",
      "4409/4409 [==============================] - 703s 159ms/step - loss: 0.2841 - acc: 0.9080 - val_loss: 0.3520 - val_acc: 0.8887\n",
      "Epoch 10/100\n",
      "4409/4409 [==============================] - 734s 166ms/step - loss: 0.2750 - acc: 0.9106 - val_loss: 0.3522 - val_acc: 0.8877\n",
      "Epoch 11/100\n",
      "4409/4409 [==============================] - 743s 169ms/step - loss: 0.2667 - acc: 0.9126 - val_loss: 0.3530 - val_acc: 0.8883\n",
      "Epoch 12/100\n",
      "4409/4409 [==============================] - 744s 169ms/step - loss: 0.2590 - acc: 0.9151 - val_loss: 0.3537 - val_acc: 0.8902\n",
      "Epoch 13/100\n",
      "4409/4409 [==============================] - 742s 168ms/step - loss: 0.2501 - acc: 0.9176 - val_loss: 0.3557 - val_acc: 0.8899\n",
      "Epoch 14/100\n",
      "4409/4409 [==============================] - 737s 167ms/step - loss: 0.2460 - acc: 0.9187 - val_loss: 0.3562 - val_acc: 0.8893\n",
      "Epoch 15/100\n",
      "4409/4409 [==============================] - 699s 159ms/step - loss: 0.2428 - acc: 0.9206 - val_loss: 0.3546 - val_acc: 0.8900\n",
      "Epoch 16/100\n",
      "4409/4409 [==============================] - 698s 158ms/step - loss: 0.2372 - acc: 0.9222 - val_loss: 0.3550 - val_acc: 0.8903\n",
      "Epoch 17/100\n",
      "4409/4409 [==============================] - 702s 159ms/step - loss: 0.2337 - acc: 0.9224 - val_loss: 0.3569 - val_acc: 0.8896\n",
      "Epoch 18/100\n",
      "4409/4409 [==============================] - 694s 157ms/step - loss: 0.2293 - acc: 0.9236 - val_loss: 0.3570 - val_acc: 0.8899\n"
     ]
    }
   ],
   "source": [
    "history = fit_gen(model, model_id, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T17:34:27.303452Z",
     "start_time": "2022-05-30T17:34:15.413470Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 01:34:27,298 - INFO - trainer.py - save_model - 595 - save model success ,num=28011\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(model, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_id = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T00:31:26.927972Z",
     "start_time": "2022-05-31T00:31:17.914967Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 08:31:26,919 - INFO - trainer.py - load_model - 580 - load weights 28011\n"
     ]
    }
   ],
   "source": [
    "model = trainer.load_model(model_id)\n",
    "# 加载训练中的最优模型\n",
    "# model.load_weights(trainer.get_weight_file(model_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T00:38:32.825342Z",
     "start_time": "2022-05-31T00:38:27.516Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_path = root_path + '/res_test'\n",
    "# use_increase = True\n",
    "# 显示预测准确度、混淆矩阵，保持混淆矩阵图到root_path\n",
    "# test_path = res_test_path\n",
    "# acc, y_pred, y_true, file_test,_ = trainer.predict_data([test_path if use_increase else res_test_path], model = model,binary_threshold=0.5)\n",
    "acc, y_pred, y_true, file_test = trainer.predict_data([pred_path], model = model,binary_threshold=0.5)\n",
    "\n",
    "\n",
    "path = Plot.show_matrix(y_pred, y_true, types_num, root_path, fig_size=10)\n",
    "plt.show()\n",
    "\n",
    "print(desc_list)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_increase = True\n",
    "# 显示预测准确度、混淆矩阵，保持混淆矩阵图到root_path\n",
    "acc, y_pred, y_true, file_test = trainer.predict_data([test_path if use_increase else res_test_path], model = model,binary_threshold=optimal_threshold)\n",
    "path = Plot.show_matrix(y_pred, y_true, types_num, root_path)\n",
    "plt.show()\n",
    "\n",
    "print(desc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc: 98.51%\n",
    "0: 98.69%\n",
    "1: 98.35%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8853171155516942\n"
     ]
    }
   ],
   "source": [
    "## 测试\n",
    "\n",
    "import cv2\n",
    "from natsort import natsorted\n",
    "\n",
    "from mbsh.core.images import sort_by_file_name,load_img_data,fetch_all_files\n",
    "imgs_path0 = r'E:\\tmp\\001_0_171315_2020_09_03_05_51_257'\n",
    "\n",
    "nums = 0\n",
    "# 获取该路径下所有图片\n",
    "files = os.listdir(imgs_path0)\n",
    "files = natsorted(files)\n",
    "src_size = 224\n",
    "new_size = 224\n",
    "def read_img(path):\n",
    "    img = cv2.imdecode(np.fromfile(path, dtype=np.uint8), cv2.IMREAD_UNCHANGED) #cv2.imread(path)\n",
    "    img = cv2.resize(img, (src_size, src_size), cv2.INTER_LINEAR)\n",
    "        \n",
    "    return img\n",
    "\n",
    "# self.lesion_similar = self.beta2 * self.lesion_similar + (1 - self.beta2) * similarity\n",
    "pred = 0\n",
    "for file in files:\n",
    "    fpath = os.path.join(imgs_path0, file)\n",
    "    img = read_img(fpath)\n",
    "    \n",
    "    x = np.array(img,dtype=\"float32\")\n",
    "\n",
    "#     xx = np.random.randint(0, src_size-new_size)\n",
    "#     yy = np.random.randint(0, src_size-new_size)\n",
    "    xx=int((src_size-new_size)//2)\n",
    "    yy=int((src_size-new_size)//2)\n",
    "    x = x[xx:xx+new_size, yy:yy+new_size,:]\n",
    "    \n",
    "    if x.shape[2] != 3:\n",
    "        \n",
    "        x = x[:, :, :3]\n",
    "        \n",
    "    predictions = model.predict(np.asarray([x]), verbose=0)\n",
    "    \n",
    "    if predictions[0][0] > 0.5:\n",
    "        nums += 1\n",
    "#     pred = 0.8 * pred + (1 - 0.8) * predictions[0][0]     \n",
    "#     print(file,\": \",predictions[0][0])\n",
    "        \n",
    "print(nums/len(files))\n",
    "# 224 0.8637037037037038\n",
    "#256  0.9807407407407407\n",
    "# 232 0.9348148148148148\n",
    "#     print(file,\": \",predictions[0][0])\n",
    "# 212张\n",
    "# 224  0.37264150943396224\n",
    "# 256 0.7688679245283019\n",
    "# 300 0.9669811320754716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    y = np.random.randint(0, h-size)\n",
    "    x = np.random.randint(0, w-size)\n",
    "\n",
    "    image = image[y:y+size, x:x+size, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from mbsh.core.images import sort_by_file_name,load_img_data,fetch_all_files\n",
    "imgs_path0 = r'E:\\projects\\znyx-trainer\\job_2020\\imgs_in_out\\test\\00'\n",
    "imgs_path1 = r'E:\\projects\\znyx-trainer\\job_2020\\imgs_in_out\\test\\01'\n",
    "binary_threshold = 0.5\n",
    "pred0_0 = 0\n",
    "pred0_1 = 0\n",
    "pred1_0 = 0\n",
    "pred1_1 = 0\n",
    "\n",
    "src_size = 300\n",
    "new_size = 224\n",
    "# 获取该路径下所有图片\n",
    "files_list0=fetch_all_files(imgs_path0)\n",
    "files_list0=sort_by_file_name(files_list0)\n",
    "\n",
    "files_list1=fetch_all_files(imgs_path1)\n",
    "files_list1=sort_by_file_name(files_list1)\n",
    "label0 = [0] * len(files_list0)\n",
    "label1 = [1] * len(files_list1)\n",
    "files_list = files_list0 + files_list1\n",
    "label = label0 + label1\n",
    "x_test = []\n",
    "X = []\n",
    "def read_img(path):\n",
    "    img = cv2.imdecode(np.fromfile(path, dtype=np.uint8), cv2.IMREAD_UNCHANGED) #cv2.imread(path)\n",
    "    img = cv2.resize(img, (src_size, src_size), cv2.INTER_LINEAR)\n",
    "    return img\n",
    "\n",
    "for file in files_list0:\n",
    "    img = read_img(file)\n",
    "    x_test.append(img)\n",
    "\n",
    "for x in x_test:\n",
    "    x = np.array(x,dtype=\"float32\")\n",
    "    \n",
    "    xx = np.random.randint(0, src_size-new_size)\n",
    "    yy = np.random.randint(0, src_size-new_size)\n",
    "\n",
    "    xx=int((src_size-new_size)//2)\n",
    "    yy=int((src_size-new_size)//2)\n",
    "    x = x[xx:xx+new_size, yy:yy+new_size,:]\n",
    "    if x.shape[2] != 3:\n",
    "        x = x[:, :, :3]\n",
    "    predictions = model.predict(np.asarray([x]), verbose=0)[0][0]\n",
    "    y_pred = 1 if predictions > binary_threshold else 0\n",
    "    \n",
    "    if y_pred == 0:\n",
    "        pred0_0 += 1\n",
    "    else:\n",
    "        pred0_1 += 1\n",
    "        \n",
    "x_test = []\n",
    "X = []     \n",
    "for file in files_list1:\n",
    "    img = read_img(file)\n",
    "    x_test.append(img)\n",
    "\n",
    "for x in x_test:\n",
    "    x = np.array(x,dtype=\"float32\")\n",
    "    xx = np.random.randint(0, src_size-new_size)\n",
    "    yy = np.random.randint(0, src_size-new_size)\n",
    "\n",
    "    xx=int((src_size-new_size)//2)\n",
    "    yy=int((src_size-new_size)//2)\n",
    "    x = x[xx:xx+new_size, yy:yy+new_size,:]\n",
    "    if x.shape[2] != 3:\n",
    "        x = x[:, :, :3]\n",
    "    predictions = model.predict(np.asarray([x]), verbose=0)[0][0]\n",
    "    y_pred = 1 if predictions > binary_threshold else 0\n",
    "    \n",
    "    if y_pred == 0:\n",
    "        pred1_0 += 1\n",
    "    else:\n",
    "        pred1_1 += 1   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = (pred0_0 + pred1_1) / (pred0_0 + pred1_1 + pred0_1 + pred1_0) * 100\n",
    "acc0 = (pred0_0) / (pred0_0 +pred0_1) * 100\n",
    "acc1 = (pred1_1) / (pred1_1 + pred1_0) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:96.62%, 体外准确率:93.78%,体内准确率:99.12%\n"
     ]
    }
   ],
   "source": [
    "print(f\"准确率:{acc:.2f}%, 体外准确率:{acc0:.2f}%,体内准确率:{acc1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 直接resize224 准确率:98.51%, 体外准确率:98.69%,体内准确率:98.35%\n",
    "# 256 准确率:97.75%, 体外准确率:96.19%,体内准确率:99.12%\n",
    "# 232 准确率:98.63%, 体外准确率:98.34%,体内准确率:98.88%\n",
    "# 准确率:96.62%, 体外准确率:93.78%,体内准确率:99.12%\n",
    "# random crop\n",
    "# 256 准确率:97.71%, 体外准确率:96.32%,体内准确率:98.92%\n",
    "# 232 准确率:98.46%, 体外准确率:98.20%,体内准确率:98.69%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4884/4884 [==============================] - 8s 2ms/sample\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from mbsh.core.images import sort_by_file_name,load_img_data,fetch_all_files\n",
    "imgs_path0 = r'E:\\projects\\znyx-trainer\\job_2020\\imgs_in_out\\test\\00'\n",
    "imgs_path1 = r'E:\\projects\\znyx-trainer\\job_2020\\imgs_in_out\\test\\01'\n",
    "\n",
    "# 获取该路径下所有图片\n",
    "files_list0=fetch_all_files(imgs_path0)\n",
    "files_list0=sort_by_file_name(files_list0)\n",
    "\n",
    "files_list1=fetch_all_files(imgs_path1)\n",
    "files_list1=sort_by_file_name(files_list1)\n",
    "label0 = [0] * len(files_list0)\n",
    "label1 = [1] * len(files_list1)\n",
    "files_list = files_list0 + files_list1\n",
    "label = label0 + label1\n",
    "x_test = []\n",
    "X = []\n",
    "def read_img(path):\n",
    "    img = cv2.imdecode(np.fromfile(path, dtype=np.uint8), cv2.IMREAD_UNCHANGED) #cv2.imread(path)\n",
    "    img = cv2.resize(img, (224, 224), cv2.INTER_LINEAR)\n",
    "    return img\n",
    "\n",
    "for file in files_list:\n",
    "    img = read_img(file)\n",
    "    x_test.append(img)\n",
    "\n",
    "for x in x_test:\n",
    "    x = np.array(x,dtype=\"float32\")\n",
    "    if x.shape[2] != 3:\n",
    "        x = x[:, :, :3]\n",
    "    X.append(x)\n",
    "\n",
    "X= np.asarray(X)\n",
    "\n",
    "predictions_list = model.predict(X, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in predictions_list:\n",
    "#     print(i[0])\n",
    "    pred.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr,tpr,thresholds = roc_curve(label,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9981371244779739"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc = auc(fpr, tpr)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "optimal_threshold\n",
    "optimal_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37347806"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(fpr, tpr, lw=1)    # 画出当前分割数据的ROC曲线\n",
    "\n",
    "plt.xlim([-0.05, 1.05])     # 设置x、y轴的上下限，设置宽一点，以免和边缘重合，可以更好的观察图像的整体\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')    # 可以使用中文，但需要导入一些库即字体\n",
    "plt.title('in_out-ROC-AUS: {:.4f}'.format(roc_auc))\n",
    "\n",
    "\n",
    "plt.annotate(r'threshold={:.3f}'.format(optimal_threshold), xy=(fpr[optimal_idx], tpr[optimal_idx]), xycoords='data', xytext=(+30, -30),\n",
    "             textcoords='offset points', fontsize=12, color='blue',\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle=\"arc3,rad=.1\",color='red'))\n",
    "plt.savefig(\"roc2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
